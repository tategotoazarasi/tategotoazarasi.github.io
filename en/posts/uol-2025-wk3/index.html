<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Uol 2025 Wk3 && LeetCode Biweekly Contest 168 Solutions | Tategoto Azarasi</title>
<meta name=keywords content="competitive-programming,cpp,algorithm-analysis,time-complexity,space-complexity,formal-proof,graph-theory,weak-vertices,triangle-finding,disjoint-set-union,union-find,connectivity,shortest-path,bfs,grid-traversal,recursion,backtracking,subset-sum-problem,greedy-algorithms,number-theory,leetcode"><meta name=description content="Weak Vertices
The Problem
In graph theory, the structural integrity of a network can often be analyzed by identifying fundamental shapes within it, such as triangles. A triangle provides rigidity and is a common motif in many applications. This problem asks us to identify vertices that are not part of any triangle. A vertex i is defined as being part of a triangle if it has two distinct neighbors, j and k, which are also neighbors of each other. Our task is to find all vertices that do not satisfy this condition, which the problem statement refers to as &ldquo;weak vertices.&rdquo; The graph is given to us in the form of an adjacency matrix."><meta name=author content="Tategoto Azarasi"><link rel=canonical href=https://tategotoazarasi.github.io/en/posts/uol-2025-wk3/><link crossorigin=anonymous href=/assets/css/stylesheet.f49d66caae9ea0fd43f21f29e71a8d3e284517ed770f2aa86fa012953ad3c9ef.css integrity="sha256-9J1myq6eoP1D8h8p5xqNPihFF+13Dyqob6ASlTrTye8=" rel="preload stylesheet" as=style><link rel=icon href=https://tategotoazarasi.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://tategotoazarasi.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://tategotoazarasi.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://tategotoazarasi.github.io/apple-touch-icon.png><link rel=mask-icon href=https://tategotoazarasi.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://tategotoazarasi.github.io/en/posts/uol-2025-wk3/><link rel=alternate hreflang=zh href=https://tategotoazarasi.github.io/zh/posts/uol-2025-wk3/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link crossorigin=anonymous href=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css integrity=sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ rel=stylesheet><script crossorigin=anonymous defer integrity=sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js></script><script crossorigin=anonymous defer integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR onload=renderMathInElement(document.body) src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js></script>>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><meta property="og:url" content="https://tategotoazarasi.github.io/en/posts/uol-2025-wk3/"><meta property="og:site_name" content="Tategoto Azarasi"><meta property="og:title" content="Uol 2025 Wk3 && LeetCode Biweekly Contest 168 Solutions"><meta property="og:description" content="Weak Vertices The Problem In graph theory, the structural integrity of a network can often be analyzed by identifying fundamental shapes within it, such as triangles. A triangle provides rigidity and is a common motif in many applications. This problem asks us to identify vertices that are not part of any triangle. A vertex i is defined as being part of a triangle if it has two distinct neighbors, j and k, which are also neighbors of each other. Our task is to find all vertices that do not satisfy this condition, which the problem statement refers to as “weak vertices.” The graph is given to us in the form of an adjacency matrix."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-10-25T17:55:44+01:00"><meta property="article:modified_time" content="2025-10-25T17:55:44+01:00"><meta property="article:tag" content="Competitive-Programming"><meta property="article:tag" content="Cpp"><meta property="article:tag" content="Algorithm-Analysis"><meta property="article:tag" content="Time-Complexity"><meta property="article:tag" content="Space-Complexity"><meta property="article:tag" content="Formal-Proof"><meta name=twitter:card content="summary"><meta name=twitter:title content="Uol 2025 Wk3 && LeetCode Biweekly Contest 168 Solutions"><meta name=twitter:description content="Weak Vertices
The Problem
In graph theory, the structural integrity of a network can often be analyzed by identifying fundamental shapes within it, such as triangles. A triangle provides rigidity and is a common motif in many applications. This problem asks us to identify vertices that are not part of any triangle. A vertex i is defined as being part of a triangle if it has two distinct neighbors, j and k, which are also neighbors of each other. Our task is to find all vertices that do not satisfy this condition, which the problem statement refers to as &ldquo;weak vertices.&rdquo; The graph is given to us in the form of an adjacency matrix."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://tategotoazarasi.github.io/en/posts/"},{"@type":"ListItem","position":2,"name":"Uol 2025 Wk3 \u0026\u0026 LeetCode Biweekly Contest 168 Solutions","item":"https://tategotoazarasi.github.io/en/posts/uol-2025-wk3/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Uol 2025 Wk3 \u0026\u0026 LeetCode Biweekly Contest 168 Solutions","name":"Uol 2025 Wk3 \u0026\u0026 LeetCode Biweekly Contest 168 Solutions","description":"Weak Vertices The Problem In graph theory, the structural integrity of a network can often be analyzed by identifying fundamental shapes within it, such as triangles. A triangle provides rigidity and is a common motif in many applications. This problem asks us to identify vertices that are not part of any triangle. A vertex i is defined as being part of a triangle if it has two distinct neighbors, j and k, which are also neighbors of each other. Our task is to find all vertices that do not satisfy this condition, which the problem statement refers to as \u0026ldquo;weak vertices.\u0026rdquo; The graph is given to us in the form of an adjacency matrix.\n","keywords":["competitive-programming","cpp","algorithm-analysis","time-complexity","space-complexity","formal-proof","graph-theory","weak-vertices","triangle-finding","disjoint-set-union","union-find","connectivity","shortest-path","bfs","grid-traversal","recursion","backtracking","subset-sum-problem","greedy-algorithms","number-theory","leetcode"],"articleBody":"Weak Vertices The Problem In graph theory, the structural integrity of a network can often be analyzed by identifying fundamental shapes within it, such as triangles. A triangle provides rigidity and is a common motif in many applications. This problem asks us to identify vertices that are not part of any triangle. A vertex i is defined as being part of a triangle if it has two distinct neighbors, j and k, which are also neighbors of each other. Our task is to find all vertices that do not satisfy this condition, which the problem statement refers to as “weak vertices.” The graph is given to us in the form of an adjacency matrix.\nMy Code My approach is a direct simulation of the definition. For each vertex, I iterate through all pairs of its neighbors and check if they are connected.\n// Iterate through each vertex `i` from 0 to n-1 to check if it's weak. for(int i=0; i\u003cn; i++) { // A flag to track if vertex `i` is part of any triangle. // We initialize it to true, assuming `i` is weak until proven otherwise. bool flag = true; // Iterate through all neighbors of `i`. // The outer loop picks the first neighbor, `j`. for(int j=0; j\u003csiblings[i].size(); j++) { // The inner loop picks the second neighbor, `k`. // We start from j+1 to ensure that we consider each pair of neighbors only once. for(int k=j+1; k\u003csiblings[i].size(); k++) { // Check if the two neighbors of `i`, namely `siblings[i][j]` and `siblings[i][k]`, // are connected to each other. if(graph[siblings[i][j]][siblings[i][k]]) { // If they are connected, then vertices `i`, `j`, and `k` form a triangle. // Thus, vertex `i` is not weak. We set the flag to false. flag = false; // Since we have found a triangle involving `i`, we can stop checking for this vertex. break; } } // If the flag has been set to false, we can break out of the outer neighbor loop as well. if(!flag) { break; } } // If, after checking all pairs of neighbors, the flag is still true, // it means no triangle was found involving `i`. Thus, `i` is a weak vertex. if(flag) { cout\u003c\u003ci\u003c\u003c' '; } } My Solution The problem requires us to identify all vertices in a given undirected graph that are not part of any triangle. A vertex is considered “weak” if this condition holds. The graph’s structure is provided via an $n \\times n$ adjacency matrix, where $n$ is the number of vertices.\nMy solution directly implements the definition provided. The core of the logic revolves around exhaustively checking, for each vertex, whether the condition for being part of a triangle is met. The algorithm proceeds vertex by vertex, from $0$ to $n-1$. For each vertex, which we can call $i$, we adopt the hypothesis that it is a weak vertex. We then try to disprove this hypothesis by searching for evidence of a triangle involving $i$. A triangle involving vertex $i$ would consist of $i$ and two of its neighbors, say $j$ and $k$, where $j$ and $k$ are also connected by an edge.\nTo perform this check, my algorithm first identifies all neighbors of the vertex $i$. This is done by reading the adjacency matrix during the input phase and storing the neighbors of each vertex in an adjacency list representation, which I’ve called siblings. This pre-processing step simplifies the neighbor lookup process. For a given vertex $i$, siblings[i] contains a list of all vertices $j$ such that there is an edge between $i$ and $j$.\nWith the list of neighbors for vertex $i$ at hand, the next step is to examine all possible pairs of these neighbors. If vertex $i$ has $d_i$ neighbors, there are $\\binom{d_i}{2}$ such pairs. I use a pair of nested loops to iterate through every unique pair of neighbors. Let the neighbors be indexed from $0$ to $d_i-1$ in the siblings[i] list. The outer loop selects a neighbor at index $j$, and the inner loop selects another neighbor at index $k$, where $k \u003e j$. This ensures that each pair is considered exactly once and avoids redundant checks (e.g., checking both $(j, k)$ and $(k, j)$) and self-comparisons (where $j=k$).\nFor each pair of neighbors, say vertex $u$ (from siblings[i][j]) and vertex $v$ (from siblings[i][k]), the algorithm checks if there is an edge connecting $u$ and $v$. This check is efficiently performed by looking up the entry in the adjacency matrix, graph[u][v]. If this entry is true (or 1), it signifies that the edge $(u, v)$ exists. The existence of edges $(i, u)$, $(i, v)$, and $(u, v)$ confirms the presence of a triangle ${i, u, v}$.\nA boolean variable, flag, is used to maintain the status of the current vertex $i$. It is initialized to true, representing the initial assumption that $i$ is weak. As soon as the algorithm finds a single pair of neighbors of $i$ that are connected to each other, it has found a triangle involving $i$. At this point, the hypothesis that $i$ is weak is disproven. The flag is set to false, and since we only need to find one triangle to disqualify a vertex from being weak, the search for this vertex $i$ can be terminated immediately. The break statements are used to exit the inner and outer loops prematurely to improve efficiency.\nIf the nested loops complete their execution without the flag ever being set to false, it means that for every pair of neighbors of $i$, no direct edge exists between them. This exhaustively proves that there are no triangles involving vertex $i$. Therefore, the initial hypothesis holds, and vertex $i$ is indeed a weak vertex. In this case, the algorithm prints the index $i$. This entire process is repeated for all vertices in the graph, ensuring that every vertex is correctly classified.\nTo formally prove the correctness of this algorithm, let us use the language of predicate logic. Let $G=(V, E)$ be the graph, where $V={0, 1, \\dots, n-1}$ is the set of vertices and $E$ is the set of edges. Let $A$ be the adjacency matrix representation of $G$, such that $A_{uv} = 1$ if $(u,v) \\in E$, and $A_{uv} = 0$ otherwise. A vertex $i \\in V$ is defined as being part of a triangle, let’s denote this property as $T(i)$, if and only if: $T(i) \\iff \\exists j, k \\in V \\text{ such that } (j \\neq i) \\land (k \\neq i) \\land (j \\neq k) \\land (A_{ij}=1) \\land (A_{ik}=1) \\land (A_{jk}=1)$. A vertex $i$ is weak, let’s denote this as $W(i)$, if it is not part of any triangle: $W(i) \\iff \\neg T(i) \\iff \\neg (\\exists j, k \\in V : (j \\neq i) \\land (k \\neq i) \\land (j \\neq k) \\land A_{ij}=1 \\land A_{ik}=1 \\land A_{jk}=1)$. By De Morgan’s laws, this is equivalent to: $W(i) \\iff \\forall j, k \\in V, \\neg ((j \\neq i) \\land (k \\neq i) \\land (j \\neq k) \\land A_{ij}=1 \\land A_{ik}=1 \\land A_{jk}=1)$. This simplifies to: $W(i) \\iff \\forall j, k \\in V, ((A_{ij}=1) \\land (A_{ik}=1)) \\implies (A_{jk}=0 \\lor i=j \\lor i=k \\lor j=k)$. Let $N(i)$ be the set of neighbors of $i$, i.e., $N(i) = {j \\in V \\mid A_{ij}=1}$. The condition for being in a triangle can be restated as: $T(i) \\iff \\exists j, k \\in N(i) \\text{ such that } (j \\neq k) \\land (A_{jk}=1)$. Consequently, the condition for being a weak vertex is: $W(i) \\iff \\forall j, k \\in N(i), (j=k) \\lor (A_{jk}=0)$. Since we are only interested in pairs of distinct neighbors, this is equivalent to: $W(i) \\iff \\forall j, k \\in N(i) \\text{ with } j \\neq k, \\text{ it holds that } A_{jk}=0$. My algorithm’s logic is a direct implementation of this final statement. The outer for loop ensures that every vertex $i \\in V$ is considered. For each $i$, the nested loops iterate through all unique pairs of distinct neighbors ${j, k} \\subseteq N(i)$. The condition if(graph[siblings[i][j]][siblings[i][k]]) is a direct check for whether $A_{jk}=1$. If this condition is ever true, the flag is set to false, correctly concluding that $\\neg W(i)$ is true. If the loops complete without this condition ever being met, it means that for all pairs of distinct neighbors ${j, k}$, $A_{jk}=0$, which is the definition of $W(i)$. Thus, the algorithm correctly identifies and prints precisely the set of all weak vertices. The correctness is therefore established.\nTime and Space Complexity The analysis of the algorithm’s complexity is crucial for understanding its performance, especially as the size of the graph grows.\nTime Complexity: The dominant part of the algorithm is the set of nested loops that execute for each vertex. Let’s analyze the work done. The main process is enclosed in a for loop that iterates from $i=0$ to $n-1$, where $n$ is the number of vertices. This loop runs $n$ times. Inside this loop, for each vertex $i$, we perform a check for triangle formation. This check involves iterating through pairs of neighbors of $i$. Let $d_i$ denote the degree of vertex $i$, which is the number of neighbors it has (siblings[i].size()). The two nested loops are designed to select every unique pair of these $d_i$ neighbors. The number of such pairs is given by the binomial coefficient $\\binom{d_i}{2} = \\frac{d_i(d_i-1)}{2}$. For each pair, a constant time lookup is performed in the adjacency matrix. Therefore, the total number of operations for a single vertex $i$ is proportional to $d_i^2$. Summing this over all vertices, the total time complexity $T(n)$ is given by: $T(n) = \\sum_{i=0}^{n-1} O(d_i^2) = O(\\sum_{i=0}^{n-1} d_i^2)$. In the worst-case scenario, the graph is a complete graph ($K_n$), where every vertex is connected to every other vertex. In this case, the degree of every vertex is $d_i = n-1$. The time complexity becomes: $T(n) = O(\\sum_{i=0}^{n-1} (n-1)^2) = O(n \\cdot (n-1)^2) = O(n^3)$. This cubic complexity indicates that the algorithm is well-suited for graphs with a small number of vertices, as specified by the problem constraints ($n \\le 20$), where $20^3 = 8000$, which is computationally very feasible.\nTo prove this formally, let $C$ be the maximum cost of a single check inside the innermost loop (a constant). The total number of operations, $T_{ops}(n)$, can be bounded by: $T_{ops}(n) \\le \\sum_{i=0}^{n-1} C \\cdot \\frac{d_i(d_i-1)}{2}$. Since $d_i \\le n-1$ for any vertex $i$, we can establish an upper bound: $T_{ops}(n) \\le \\sum_{i=0}^{n-1} C \\cdot \\frac{(n-1)(n-2)}{2} = n \\cdot C \\cdot \\frac{(n-1)(n-2)}{2}$. This expression is a polynomial of degree 3 in $n$. According to the definition of Big-O notation, there must exist constants $c \u003e 0$ and $n_0$ such that for all $n \\ge n_0$, $T_{ops}(n) \\le c \\cdot n^3$. Our derived upper bound $n \\cdot C \\cdot \\frac{(n-1)(n-2)}{2}$ clearly satisfies this, so the time complexity is formally $O(n^3)$.\nSpace Complexity: The space complexity is determined by the amount of memory required to store the graph structure. My solution uses two primary data structures for this purpose:\nAn adjacency matrix graph, which is an $n \\times n$ matrix of booleans. This requires $O(n^2)$ space. An adjacency list siblings, which is a vector of vectors. In the worst case of a dense graph, the total number of entries across all lists is $2|E|$, where $|E|$ is the number of edges. For a complete graph, $|E| = \\binom{n}{2} = O(n^2)$. Thus, the adjacency list also requires $O(n^2)$ space in the worst case. Other variables, such as loop counters and the boolean flag, use only a constant amount of additional space, $O(1)$. Therefore, the total space complexity is dominated by the graph representations, making it $O(n^2)$. Formally, let $S(n)$ be the total space required. $S(n) = \\text{space}(\\text{graph}) + \\text{space}(\\text{siblings}) + \\text{space}(\\text{other})$. $\\text{space}(\\text{graph}) = n \\times n \\times \\text{sizeof(bool)} = \\Theta(n^2)$. $\\text{space}(\\text{siblings}) = \\sum_{i=0}^{n-1} d_i \\times \\text{sizeof(int)} = 2|E| \\times \\text{sizeof(int)} = O(|E|)$. Since $|E| \\le n^2$, we have $\\text{space}(\\text{siblings}) = O(n^2)$. $\\text{space}(\\text{other}) = O(1)$. So, $S(n) = \\Theta(n^2) + O(n^2) + O(1) = O(n^2)$. This concludes the formal complexity analysis.\nWhere’s my Internet? The Problem This problem presents a scenario of houses in a new town that need to be connected to the internet. We are given $N$ houses, numbered 1 to $N$, and $M$ existing network cable connections between pairs of houses. House 1 is the source of the internet connection for the entire town. A house is considered connected to the internet if it is house 1, or if it is connected by a cable to another house that is already connected. The task is to identify and list all the houses that are not yet connected to the internet. If all houses are connected, we should report that.\nMy Code This problem is about connectivity in a graph. I recognized it as a perfect use case for a Disjoint Set Union (DSU), also known as a Union-Find data structure. I model the houses as nodes in a graph and the cables as edges. All houses that can reach each other form a connected component, which the DSU can track efficiently.\n/// \\brief Disjoint Set Union (Union-Find) class class UnionFind { private: vector\u003cint\u003e parent; // parent[i] stores the parent of element i vector\u003cint\u003e rank; // Used for union by rank optimization public: // Constructor initializes n elements, each in its own set. explicit UnionFind(int n) { parent.resize(n); rank.resize(n, 0); // Initially, each element is its own parent. for(int i = 0; i \u003c n; i++) { parent[i] = i; } } // Finds the representative (root) of the set containing x, with path compression. int find(int x) { if(parent[x] != x) { parent[x] = find(parent[x]); // Path compression } return parent[x]; } // Unites the sets containing x and y, using union by rank. void unite(int x, int y) { int rootX = find(x); int rootY = find(y); if(rootX != rootY) { // Only unite if they are in different sets if(rank[rootX] \u003c rank[rootY]) { parent[rootX] = rootY; } else { parent[rootY] = rootX; if(rank[rootX] == rank[rootY]) { rank[rootX]++; } } } } // Checks if x and y are in the same set. bool same(int x, int y) { return find(x) == find(y); } }; // Main logic int N,M; cin \u003e\u003e N \u003e\u003e M; // Create a DSU structure for N+1 houses (using 1-based indexing). UnionFind uf = UnionFind(N+1); while(M--) { int a, b; cin \u003e\u003e a \u003e\u003e b; // Each cable connection means we unite the sets of the two houses. uf.unite(a,b); } bool flag = false; // Flag to check if any house is unconnected. // Iterate through all houses from 2 to N. for(int i=2; i\u003c=N; i++) { // A house `i` is connected to the internet if it's in the same set as house 1. if(!uf.same(i,1)) { cout \u003c\u003c i \u003c\u003c endl; // If not, print its number. flag = true; } } // If the flag was never set, all houses were connected. if(!flag) { cout \u003c\u003c \"Connected\"; } My Solution The problem asks us to determine which houses, in a network of $N$ houses and $M$ cable connections, are not connected to the internet. The internet originates from house 1. Connectivity is transitive: if house A is connected to house B, and B is connected to C, then A, B, and C are all mutually connected. A house has internet if it is part of the same connected block as house 1.\nThis problem can be modeled as finding the connected components of a graph. The houses are the vertices, and the cables are the edges. All houses in the same connected component as vertex 1 will have internet access. All houses in other components will not. My chosen data structure to solve this is the Disjoint Set Union (DSU) or Union-Find data structure. This structure is specifically designed to keep track of a partition of a set of elements into a number of disjoint, non-overlapping subsets. In our case, the set of elements is the set of houses, and each subset will represent a connected component.\nInitially, I treat each of the $N$ houses as being in its own separate component. The DSU is initialized with $N+1$ elements (to allow for 1-based indexing from 1 to $N$), where each element is its own “parent” or “representative,” signifying $N$ disjoint sets.\nThen, I process the $M$ cable connections one by one. Each connection between two houses, say house a and house b, signifies that these two houses are directly connected. In the context of our connected components, this means that the component containing a and the component containing b should now be considered a single, larger component. The unite(a, b) operation in my DSU class accomplishes this. It finds the representatives of the sets containing a and b. If they are not already the same, it merges the two sets. To keep the structure efficient, I employ two standard optimizations: union by rank and path compression.\nUnion by Rank: When merging two sets, the representative of the set with a smaller “rank” (a rough measure of the tree’s depth) is attached to the representative of the set with a larger rank. This helps to keep the trees representing the sets from becoming too tall and unbalanced, which would slow down the find operation. Path Compression: During a find(x) operation, which traverses the path from element x to its root representative, we make every node on that path point directly to the root. This dramatically flattens the tree structure over time, making subsequent find operations on any of those elements (or their descendants) nearly constant time. After processing all $M$ cable connections, the DSU structure accurately reflects the connected components of the housing network. Each set in the DSU corresponds to one connected component. The final step is to determine which houses are connected to the internet. A house i has internet if and only if it is in the same connected component as house 1. The DSU provides a highly efficient way to check this: the same(i, 1) function. This function returns true if i and 1 belong to the same set (i.e., they have the same root representative) and false otherwise.\nMy code iterates through all houses from 2 to $N$. For each house i, it calls uf.same(i, 1). If this returns false, it means house i is not in the same component as house 1 and therefore lacks an internet connection. The number i is then printed. If the loop completes and no such houses are found, it means every house from 2 to $N$ is in the same component as house 1. In this case, the program prints “Connected”.\nThe formal proof of correctness for this approach rests on the DSU’s ability to correctly model equivalence relations. The “is connected to” relation in a graph is an equivalence relation:\nReflexive: Any vertex v is connected to itself (by a path of length 0). Symmetric: If u is connected to v, then v is connected to u (since edges are undirected). Transitive: If u is connected to v and v is connected to w, then u is connected to w. An equivalence relation partitions a set into disjoint equivalence classes. In graph theory, these equivalence classes are precisely the connected components. The DSU data structure is designed to maintain such a partition. Let’s prove that after processing all edges, two vertices $u, v$ are in the same set in the DSU if and only if there is a path between them in the graph. Proof by Induction on the number of unite operations (edges processed): Base Case: Before any edges are processed ($m=0$), each vertex is in its own set. This is correct, as there are no paths between distinct vertices. Inductive Hypothesis: Assume that after processing $k$ edges, the DSU correctly represents the connected components of the graph formed by these $k$ edges. Inductive Step: Consider processing the $(k+1)$-th edge, $(u, v)$. The unite(u, v) operation merges the sets containing $u$ and $v$. In the graph, this new edge creates a path between any node in $u$’s old component and any node in $v$’s old component. Therefore, these two components should merge into one, which is exactly what the unite operation does. Any two nodes that were in the same component before remain so. Any two nodes that were in different components and are not in the newly merged component also remain in different components. Thus, the DSU partition remains correct after processing the $(k+1)$-th edge. By induction, after all $M$ edges are processed, the DSU correctly partitions the vertices into the graph’s connected components. A house i has internet if and only if there is a path from i to 1. This is equivalent to i and 1 being in the same connected component. My algorithm checks this using uf.same(i, 1). Therefore, the logic is correct. Time and Space Complexity Time Complexity: The overall time complexity is determined by three parts: initialization of the DSU, processing the $M$ cable connections, and the final check for connectivity.\nInitialization: The UnionFind constructor initializes the parent and rank arrays for $N+1$ elements. This involves a single loop that runs $N+1$ times. The complexity is $O(N)$. Processing Connections: We loop $M$ times. In each iteration, we perform two find operations and one unite operation. With the crucial optimizations of path compression and union by rank (or size), the amortized time complexity of a single find or unite operation is nearly constant. It is more formally expressed using the inverse Ackermann function, $\\alpha(N)$, which is a very slowly growing function. For all practical purposes in computing, $\\alpha(N)$ is less than 5. Thus, the cost of one operation can be considered $O(\\alpha(N))$. The total time for processing all $M$ connections is therefore $O(M \\cdot \\alpha(N))$. Final Check: We loop from house 2 to $N$, which is $N-1$ iterations. In each iteration, we perform a same(i, 1) call, which involves two find operations. The total time for this part is $O(N \\cdot \\alpha(N))$. Combining these parts, the total time complexity is $O(N + M \\cdot \\alpha(N) + N \\cdot \\alpha(N))$, which simplifies to $O((N+M)\\alpha(N))$. Given the constraints ($N, M \\le 200,000$), this is highly efficient.\nTo formally state this, let’s denote the cost of a DSU operation as $T_{dsu}(N)$. With both path compression and union by rank/size, it is known that a sequence of $m$ operations on $n$ elements takes $O(m \\cdot \\alpha(n))$ time. In our case, the initialization takes $T_{init}(N) = c_1 N$ time. The main loop performs $M$ unite operations, each of which calls find twice. This is a sequence of $3M$ operations. The final loop performs $N-1$ same operations, each calling find twice, for a total of $2(N-1)$ operations. The total number of DSU operations is $m = 3M + 2(N-1)$. The total time is $T(N, M) = T_{init}(N) + T_{ops}(N, M) = c_1 N + O((3M + 2(N-1))\\alpha(N)) = O((N+M)\\alpha(N))$. This confirms the complexity.\nSpace Complexity: The memory usage is primarily determined by the storage required for the DSU data structure.\nThe parent vector stores an integer for each of the $N+1$ houses. This requires $O(N)$ space. The rank vector also stores an integer for each of the $N+1$ houses, also requiring $O(N)$ space. The other variables are of constant size. Therefore, the total space complexity of my solution is $O(N)$. Formally, $S(N) = \\text{space}(\\text{parent}) + \\text{space}(\\text{rank}) = c_1 (N+1) + c_2 (N+1) = O(N)$.\nGrid The Problem This problem challenges us to find the shortest path on a grid. We are given an $n \\times m$ grid where each cell contains a single digit, say $k$. From a cell containing the digit $k$, we can make a “move” by jumping exactly $k$ squares in one of the four cardinal directions (up, down, left, or right). We are not allowed to jump off the grid. The goal is to find the minimum number of moves required to travel from the top-left corner (cell (0, 0)) to the bottom-right corner (cell (n-1, m-1)). If the destination is unreachable, we should report -1.\nMy Code This problem is a shortest path problem on an unweighted graph. The grid cells can be thought of as nodes, and the possible jumps as edges. A Breadth-First Search (BFS) is the classic algorithm for finding the shortest path in an unweighted graph. My implementation uses a priority queue, which makes it resemble Dijkstra’s algorithm. However, since all “edge weights” are implicitly 1 (each move counts as one step), this approach functions identically to a standard BFS and correctly finds the shortest path.\n// A struct to hold the state: coordinates (x, y) and the number of steps taken. struct state { public: int x; int y; int step; }; // Main logic int n, m; cin \u003e\u003e n \u003e\u003e m; // Read the grid from input. vector\u003cvector\u003cint\u003e\u003e grid(n, vector\u003cint\u003e(m)); for(int i = 0; i \u003c n; i++) { string line; cin \u003e\u003e line; for(int j = 0; j \u003c m; j++) { grid[i][j] = line[j] - '0'; } } // A set to keep track of visited grid cells to avoid cycles and redundant computations. unordered_set\u003cpair\u003cint, int\u003e, pair_hash, pair_equal\u003e visited{}; // A priority queue to manage states to visit. While a simple queue is sufficient // for a standard BFS, a priority queue also works correctly here because all // edge weights are uniform (1). It will explore layer by layer. // My custom comparator is not strictly necessary but was added for experimentation. auto comp = [](const state \u0026a, const state \u0026b) { return a.step \u003e b.step; }; priority_queue\u003cstate, vector\u003cstate\u003e, decltype(comp)\u003e pq{}; pq.push(state{0, 0, 0}); // Start at (0,0) with 0 steps. while(!pq.empty()) { auto top = pq.top(); pq.pop(); int x = top.x; int y = top.y; // If we have already processed this cell, skip it. if(visited.count({x, y})) { continue; } visited.insert(make_pair(x, y)); // Get the jump distance from the current cell. int jump_dist = grid[x][y]; // Define the four possible moves. pair\u003cint, int\u003e next_moves[4] = { make_pair(x + jump_dist, y), // Down make_pair(x - jump_dist, y), // Up make_pair(x, y + jump_dist), // Right make_pair(x, y - jump_dist) // Left }; for(auto [next_x, next_y]: next_moves) { // Check if the destination is reached. if(next_x == n - 1 \u0026\u0026 next_y == m - 1) { cout \u003c\u003c top.step + 1; // Found the shortest path. return 0; } // Check if the move is valid (within grid bounds) and not to a zero-jump cell. if(next_x \u003e= 0 \u0026\u0026 next_x \u003c n \u0026\u0026 next_y \u003e= 0 \u0026\u0026 next_y \u003c m \u0026\u0026 grid[next_x][next_y]!=0) { // Push the new state to the queue. pq.push(state{next_x, next_y, top.step + 1}); } } } // If the queue becomes empty and the destination was not reached, it's impossible. cout \u003c\u003c -1; My Solution This problem asks for the minimum number of moves to get from a starting cell to a target cell in a grid. This is a classic example of a shortest path problem on a graph. The graph in question can be constructed by considering each cell $(i, j)$ of the grid as a vertex. An edge exists from vertex $(i, j)$ to another vertex $(i’, j’)$ if we can legally jump from the first cell to the second in a single move. Since each move counts as 1, the graph is unweighted. The problem is then reduced to finding the shortest path from the vertex corresponding to cell $(0, 0)$ to the vertex for cell $(n-1, m-1)$.\nThe canonical algorithm for finding the shortest path in an unweighted graph is the Breadth-First Search (BFS). BFS systematically explores the graph layer by layer, starting from the source vertex. It discovers all vertices at distance 1, then all vertices at distance 2, and so on. This property guarantees that the first time BFS reaches the destination vertex, it will have done so via a shortest path.\nMy solution implements this BFS-like traversal. I use a data structure, in this case a priority queue, to store the “frontier” of the search—the set of cells that have been reached but whose neighbors have not yet been explored. A state struct is used to store the coordinates of a cell and the number of moves (step) taken to reach it. The search starts by placing the initial state, {0, 0, 0}, into the queue.\nThe main part of the algorithm is a loop that continues as long as the queue is not empty. In each iteration, it extracts a state from the queue. Let’s say we extract the state for cell $(x, y)$, reached in top.step moves. To prevent infinite loops in case of cycles and to avoid redundant computations, I use a visited set. If the cell $(x, y)$ has already been visited, we simply discard the current state and proceed to the next one. Otherwise, we mark $(x, y)$ as visited.\nNext, the algorithm determines the jump distance, $k = \\text{grid}[x][y]$, from the current cell. It then calculates the coordinates of the four potential destination cells by adding or subtracting $k$ from the current coordinates. For each potential move to a cell $(next_x, next_y)$:\nIt first checks if this new cell is the target destination, $(n-1, m-1)$. If it is, we have found a path. Since BFS explores paths in increasing order of length, this must be a shortest path. The length is the current path length (top.step) plus one more move. The program prints this number and terminates. If it’s not the destination, the algorithm verifies that the move is valid: the new coordinates must be within the grid’s boundaries ($0 \\le next_x \u003c n$ and $0 \\le next_y \u003c m$). I also added a check to ensure the jump value at the destination cell is not zero, which would create a dead end. If the move is valid, a new state {next_x, next_y, top.step + 1} is created and added to the queue for future exploration. If the main loop finishes (i.e., the queue becomes empty) and the destination has not been reached, it means that the destination cell is in a part of the graph that is not reachable from the starting cell. In this case, the algorithm prints -1.\nNow, let’s provide a formal proof of correctness. The algorithm is a variant of Dijkstra’s algorithm, which, on a graph with uniform positive edge weights (all equal to 1 in this case), behaves identically to BFS. Let’s prove that it finds the shortest path. Let $d(v)$ be the length of the shortest path from the source vertex $s$ (cell $(0,0)$) to any vertex $v$. We want to prove that when the algorithm terminates upon reaching the destination $t$ (cell $(n-1, m-1))$, the path length it found, step+1, is equal to $d(t)$. Let’s prove by induction that when a vertex $v$ is extracted from the priority queue, the value v.step is equal to $d(v)$.\nBase Case: The first vertex extracted is the source $s$, with s.step = 0. The shortest path from a source to itself is indeed 0. So, the base case holds. Inductive Hypothesis: Assume for all vertices $u$ extracted from the queue before a vertex $v$, it holds that u.step = $d(u)$. Inductive Step: Let $v$ be the next vertex to be extracted from the queue. Let $u$ be the vertex that caused $v$ to be added to the queue. This means there is an edge $(u, v)$ and v.step = u.step + 1. By the inductive hypothesis, u.step = d(u). Therefore, v.step = d(u) + 1. This means there is a path to $v$ of length v.step. We now need to show this is the shortest path. Consider any path from $s$ to $v$. Let this path be $s=v_0, v_1, \\dots, v_k=v$. Let $v_i$ be the first vertex on this path that has not yet been extracted from the queue. All its predecessors $v_0, \\dots, v_{i-1}$ have been extracted. Let $v_{i-1}$ be the immediate predecessor. When $v_{i-1}$ was processed, the state for $v_i$ would have been pushed to the queue with a step count of v_{i-1}.step + 1. By the inductive hypothesis, v_{i-1}.step = d(v_{i-1}) = i-1. So, $v_i$ is in the queue with a step value of $i$. Since my priority queue (and a standard BFS queue) processes nodes in non-decreasing order of their step value, $v$ could not have been extracted before $v_i$ if v.step \u003e v_i.step. Since the path $s, \\dots, v_k=v$ has length $k$, we know $d(v) \\le k$. The vertex $v_i$ on this path is in the queue with step value $i$. The length of the path to $v$ is $k$. Any path to $v$ must pass through a frontier node. The algorithm always expands the node on the frontier with the smallest step count. Therefore, when it reaches $v$, it must have done so via a path of length $d(v)$. So v.step = d(v). Since the algorithm terminates as soon as it reaches the destination $t$, the step count at that point will be $d(t)$, the shortest path length. If $t$ is never reached, the queue will become empty, correctly indicating no path exists. Time and Space Complexity Time Complexity: The time complexity of this search algorithm depends on the number of vertices and edges in the graph. In our grid, the number of vertices $|V|$ is $n \\times m$. Each vertex has at most 4 outgoing edges. So, the number of edges $|E|$ is at most $4 \\times n \\times m$, which is $O(nm)$. The main loop runs as long as the priority queue is not empty. Each vertex (cell) is added to the queue at most once because of the visited set. When we process a vertex, we do a constant number of operations (checking its 4 neighbors). The operations on the priority queue (push and pop) take logarithmic time in the size of the queue. The maximum size of the queue is $|V|=nm$. So, the complexity is dominated by the queue operations for each vertex and edge. The total time complexity is $O(|V| \\log |V| + |E|) = O(nm \\log(nm) + 4nm) = O(nm \\log(nm))$. Note: If a standard queue were used for a pure BFS, the enqueue and dequeue operations would be $O(1)$, leading to a time complexity of $O(|V|+|E|) = O(nm)$. Since my solution uses a priority queue, the logarithmic factor is included in the analysis.\nLet’s formalize this. Let $N = n \\times m$. The number of vertices is $N$. The number of edges is at most $4N$. The algorithm is essentially Dijkstra’s.\nPushing the initial state: $O(\\log N)$. The while loop runs at most $N$ times (once per vertex). Inside the loop: pq.pop(): $O(\\log N)$. visited.count() and visited.insert() on an unordered set are on average $O(1)$. The inner loop runs 4 times. Inside the inner loop, pq.push(): $O(\\log N)$. Total time: $N \\times (O(\\log N) + O(1) + 4 \\times O(\\log N)) = N \\times O(\\log N) = O(nm \\log(nm))$. Space Complexity: The space required is determined by the data structures used to store the grid, the visited set, and the priority queue.\nGrid: The grid itself is an $n \\times m$ matrix, requiring $O(nm)$ space. Visited Set: In the worst case, the visited set can store a pair of coordinates for every cell in the grid. This requires $O(nm)$ space. Priority Queue: The priority queue can also, in the worst case, hold a state for every cell in the grid. This also requires $O(nm)$ space. Summing these up, the total space complexity is $O(nm) + O(nm) + O(nm) = O(nm)$. Formally, $S(n, m) = \\text{space}(\\text{grid}) + \\text{space}(\\text{visited}) + \\text{space}(\\text{pq})$. Let $N=nm$. $S(n, m) = c_1 N + c_2 N + c_3 N = O(N) = O(nm)$.\nOddities The Problem This is a fundamental programming exercise focused on the concept of parity. We are asked to determine whether a given integer is odd or even. An integer $n$ is defined as even if it is a multiple of two (i.e., can be expressed as $n=2k$ for some integer $k$), and odd otherwise. The program needs to handle multiple test cases, reading an integer and printing whether it is odd or even.\nMy Code The solution is straightforward and relies on the modulo operator (%), which gives the remainder of a division. A number is even if its remainder when divided by 2 is 0, and odd if the remainder is 1. I also handle negative numbers by taking the absolute value first.\n// The number of test cases `n` is read first. int n; cin\u003e\u003en; // Loop `n` times to process each test case. while(n--) { int x; cin\u003e\u003ex; // To correctly handle negative numbers like -5, we first take the absolute value. // Then, we use the modulo operator (%) to find the remainder when divided by 2. // If abs(x) % 2 is 1, the number is odd. // If abs(x) % 2 is 0, the number is even. // The ternary operator `(condition ? value_if_true : value_if_false)` // is used for a compact output string. cout \u003c\u003c x \u003c\u003c \" is \" \u003c\u003c ((abs(x) % 2 == 1) ? \"odd\" : \"even\") \u003c\u003c endl; } My Solution The problem is to classify a given integer $x$ as either “even” or “odd”. The mathematical definition of parity is central to the solution. An integer $z$ is called even if it can be written as $z=2k$ for some integer $k$. An integer is called odd if it can be written as $z=2k+1$ for some integer $k$. This definition is a direct consequence of the Division Algorithm from number theory, which states that for any integer $a$ and any positive integer $d$, there exist unique integers $q$ (quotient) and $r$ (remainder) such that $a = dq + r$ and $0 \\le r \u003c d$.\nWhen we apply the Division Algorithm with the divisor $d=2$, we find that for any integer $x$, there exist unique integers $q$ and $r$ such that $x = 2q + r$ and $0 \\le r \u003c 2$. This means the only possible values for the remainder $r$ are 0 or 1.\nIf $r=0$, then $x=2q$. By definition, $x$ is an even number. If $r=1$, then $x=2q+1$. By definition, $x$ is an odd number. This provides a clear and unambiguous method for determining the parity of any integer: we just need to find its remainder when divided by 2. The modulo operator (%) in C++ and many other programming languages is designed to compute this remainder. So, x % 2 will yield the remainder of $x$ divided by 2.\nA small subtlety arises with negative numbers. The behavior of the modulo operator with negative operands can differ across programming languages. In C++, the result of a % n has the same sign as a. For example, -5 % 2 results in -1. To ensure a consistent and simple check, my solution first takes the absolute value of the input integer x using abs(x). This maps both positive and negative integers to their non-negative counterparts. For any non-negative integer, abs(x) % 2 will be either 0 (for even numbers) or 1 (for odd numbers). This approach works because the parity of an integer $x$ is the same as the parity of its absolute value, $|x|$. If $x = 2k$, then $|x| = |2k| = 2|k|$, which is even. If $x = 2k+1$, then $|x|=|2k+1|$. If $k \\ge 0$, $|x|=2k+1$, which is odd. If $k \u003c 0$, say $k’ = -k \u003e 0$, then $x = -2k’+1$. $|x| = |-(2k’-1)| = 2k’-1 = 2(k’-1)+1$, which is also odd. Thus, checking abs(x) % 2 is a robust method.\nMy code implements this logic concisely. It reads an integer $x$, computes abs(x) % 2, and uses a ternary operator to select the correct string (“odd” or “even”) based on whether the result is 1 or 0.\nThe formal proof of correctness is grounded in the Division Algorithm as explained above. Let $P(x)$ be the proposition “the algorithm correctly determines the parity of integer $x$”. We need to prove $\\forall x \\in \\mathbb{Z}, P(x)$. Case 1: $x$ is even. By definition, $\\exists k \\in \\mathbb{Z}$ such that $x = 2k$. Then $|x| = |2k| = 2|k|$. The expression abs(x) % 2 in the code computes $|x| \\pmod 2$. $|x| \\pmod 2 = (2|k|) \\pmod 2 = 0$. The code checks if this value is 1. It is not. The ternary operator (0 == 1 ? \"odd\" : \"even\") evaluates to “even”. The algorithm correctly outputs that $x$ is even. Case 2: $x$ is odd. By definition, $\\exists k \\in \\mathbb{Z}$ such that $x = 2k+1$. Then $|x| = |2k+1|$. The expression abs(x) % 2 computes $|x| \\pmod 2$. We know $|x| \\pmod 2 = ((2k+1) \\pmod 2 \\text{ if } 2k+1 \\ge 0) \\lor ((-(2k+1)) \\pmod 2 \\text{ if } 2k+1 \u003c 0)$. In the first subcase, $(2k+1) \\pmod 2 = 1$. In the second subcase, let $k’ = -k-1$. Then $-(2k+1) = -2k-1 = -2(k’+1)-1 = 2(-k’-1)+1$. This is of the form $2q+1$, so its remainder when divided by 2 is 1. In all subcases, if $x$ is odd, $|x| \\pmod 2 = 1$. The code checks if this value is 1. It is. The ternary operator (1 == 1 ? \"odd\" : \"even\") evaluates to “odd”. The algorithm correctly outputs that $x$ is odd. Since the algorithm is correct for both even and odd integers, it is correct for all integers.\nTime and Space Complexity Time Complexity: The algorithm processes each of the $n$ test cases independently inside a while loop. For each test case, the work done is constant. It involves:\nReading an integer (cin). Calling abs(), which is a constant-time operation. Performing a modulo operation (%), which is a constant-time operation for native integer types. Performing a comparison (==). Printing the result (cout). All these steps take a small, constant amount of time, let’s call it $C$. The total time complexity is therefore the number of test cases $n$ multiplied by this constant time, which is $O(n)$. Formally, let $T(n)$ be the total time for $n$ test cases. $T(n) = \\sum_{i=1}^{n} C_i$, where $C_i$ is the constant time taken for the $i$-th test case. So, $T(n) = n \\cdot C$. By the definition of Big-O notation, this is $O(n)$.\nSpace Complexity: The algorithm uses only a few variables to store the number of test cases (n) and the integer for the current test case (x). The amount of memory used does not depend on the magnitude of the input numbers (within the limits of the int type) or the number of test cases. Therefore, the space complexity is constant, $O(1)$.\nFormally, $S(n) = \\text{space}(n) + \\text{space}(x) = \\text{sizeof(int)} + \\text{sizeof(int)} = C’$, where $C’$ is a constant. This is $O(1)$.\nCounting Chocolate The Problem This problem is a variation of the classic Partition Problem. We are given a collection of $n$ boxes of chocolate, each containing a certain number of pieces. We need to determine if it’s possible to divide these boxes between two people, John and Sam, such that the total number of chocolate pieces each person receives is exactly the same. All boxes must be distributed.\nMy Code This problem can be solved by checking if there exists a subset of the boxes whose total number of pieces is exactly half of the grand total. If such a subset exists, we can give it to John, and the remaining boxes will automatically sum to the same amount for Sam. This is a subset sum problem. Given the small constraints, I opted for a recursive (backtracking) solution to explore all possible subsets.\n// Recursive function to solve the subset sum problem. // a: the vector of chocolate pieces in each box. // john: current sum of pieces for John. // sam: current sum of pieces for Sam. // sp: the starting point (index) in the vector `a` for the current recursive call. // target: the target sum for each person (total_sum / 2). bool solve(const vector\u003cint\u003e\u0026 a, int john, int sam, int sp, int target) { // Base case: if we have considered all boxes. if(sp == a.size()) { // If we reached the end, a solution is only found if one person hit the target exactly. // However, the checks below make this redundant. return false; } // Success condition: if either person's sum has reached the target. if(john == target || sam == target) { return true; } // Pruning: if either person's sum has exceeded the target, this path is invalid. if(john \u003e target || sam \u003e target) { return false; } // Recursive step: explore two choices for the box at index `sp`. // Choice 1: Give the current box to John. // Choice 2: Give the current box to Sam. // The `||` (OR) means we return true if either choice leads to a solution. return solve(a, john + a[sp], sam, sp + 1, target) || solve(a, john, sam + a[sp], sp + 1, target); } // Main logic int n; cin\u003e\u003en; vector\u003cint\u003e a = vector\u003cint\u003e(n); int sum = 0; for(int i=0; i\u003cn; i++) { cin\u003e\u003ea[i]; sum += a[i]; } // A crucial initial check: If the total sum of chocolates is odd, // it's impossible to divide it into two equal integer halves. if(sum % 2 == 1) { cout \u003c\u003c \"NO\"; return 0; } // Call the recursive solver. We start with both sums at 0, from the first box (index 0), // with the target being half the total sum. if(solve(a, 0, 0, 0, sum / 2)) { cout \u003c\u003c \"YES\"; } else { cout \u003c\u003c \"NO\"; } My Solution The problem asks if a given set of integers (the number of chocolates in each box) can be partitioned into two subsets with equal sums. Let the set of chocolate counts be $S = {a_1, a_2, \\dots, a_n}$. We are looking for a partition of $S$ into two disjoint subsets, $S_1$ and $S_2$, such that $S_1 \\cup S_2 = S$, $S_1 \\cap S_2 = \\emptyset$, and $\\sum_{x \\in S_1} x = \\sum_{y \\in S_2} y$.\nFirst, a simple but powerful observation can be made. If the two subsets have equal sums, say $K$, then the total sum of all chocolates, $\\sum_{z \\in S} z$, must be $K+K = 2K$. This implies that the total sum must be an even number. If the total sum is odd, it’s mathematically impossible to partition it into two equal integer sums. My algorithm begins with this check: it calculates the total sum of all pieces, and if this sum is odd, it immediately prints “NO” and terminates. This is a valid and efficient pruning of the entire problem space.\nIf the total sum is even, let it be $2K$. Our goal is now to find a subset $S_1 \\subseteq S$ whose elements sum up to exactly $K$. If we can find such a subset, then the elements in the remaining subset $S_2 = S \\setminus S_1$ will have a sum of $2K - K = K$, satisfying the condition. So, the problem is transformed into the Subset Sum Problem: given a set of integers, is there a non-empty subset whose sum is equal to a given integer $K$?\nThe Subset Sum Problem is a classic NP-complete problem. This means that there is no known algorithm that can solve it in polynomial time for all inputs. However, for small inputs, we can solve it using methods like dynamic programming or, as I have chosen, recursion with backtracking. My solve function embodies this backtracking approach.\nThe function solve(a, john, sam, sp, target) explores the possibilities. The parameters represent the current state of the decision-making process: john and sam are the current sums for the two people, sp is the index of the current box we are considering, and target is the desired sum $K$.\nThe logic of the recursion is as follows: For each box a[sp], we have two choices:\nGive the box to John. Give the box to Sam. The function explores both of these choices through recursive calls. In the first call, solve(a, john + a[sp], sam, sp + 1, target), we add the current box’s value to John’s total and move on to consider the next box (sp + 1). In the second call, solve(a, john, sam + a[sp], sp + 1, target), we explore the alternative where the box is given to Sam. The || (logical OR) operator combines the results. If either of these branches of exploration eventually leads to a solution, the function returns true.\nThe recursion has several base cases and pruning conditions:\nSuccess: If at any point john == target (or sam == target), we have successfully found a subset that sums to the target. We can immediately return true. This true value will propagate up the call stack. Pruning: If john \u003e target or sam \u003e target, it means the current path has already overshot the target sum. Since all chocolate counts are positive, this sum will only increase. This branch cannot lead to a solution, so we can prune it by returning false. Failure: If sp == a.size(), it means we have considered every box. If we have not yet returned true, it means this particular distribution of boxes did not result in either person having a sum of exactly $K$. We return false. The initial call to the function is solve(a, 0, 0, 0, sum/2). This starts the process with empty sums for both people, considering the first box, with the target being half of the total sum.\nThe correctness of this backtracking algorithm stems from the fact that it explores the entire search space of all possible partitions. The decision for each box (a[sp]) to go to John or Sam creates a binary decision tree. The leaves of this tree represent all $2^n$ possible ways to distribute the $n$ boxes. The algorithm systematically traverses this tree. The pruning conditions (john \u003e target, sam \u003e target) help to cut off branches that are guaranteed not to lead to a solution, but they do not affect correctness because they only discard invalid paths. Since the algorithm explores every valid possibility, if a solution exists, it is guaranteed to be found. If the function returns false, it means the exhaustive search completed without finding any valid partition.\nLet $P(S, K)$ be the problem of finding if a subset of $S$ sums to $K$. My recursive function, let’s call it $R(i, j_s, s_s)$, where $i$ is the index of the item to consider, and $j_s, s_s$ are the current sums, computes whether a partition is possible. The correctness can be formally proven by induction on the number of items remaining, $k = n-i$.\nBase Case ($k=0$, i.e., $i=n$): No items are left. A solution exists if and only if $j_s=K$ or $s_s=K$. My function’s base cases cover this. Inductive Hypothesis: Assume $R(i+1, \\dots)$ correctly solves the problem for the sub-array starting at $i+1$. Inductive Step: To solve for $R(i, j_s, s_s)$, we consider item $a_i$. A solution exists if (a) we give $a_i$ to John and a solution exists for the rest, i.e., $R(i+1, j_s+a_i, s_s)$ is true, OR (b) we give $a_i$ to Sam and a solution exists for the rest, i.e., $R(i+1, j_s, s_s+a_i)$ is true. This is precisely what the line return solve(...) || solve(...) does. By the inductive hypothesis, the recursive calls are correct. Therefore, the logic for step $i$ is also correct. Time and Space Complexity Time Complexity: The recursive algorithm, in its pure form, explores a binary tree of decisions. For each of the $n$ boxes, there are two choices. This leads to a total of $2^n$ possible distributions (leaves in the decision tree). The algorithm, in the worst case, might have to explore all of them. At each step of the recursion, a constant amount of work is done. Therefore, the time complexity is exponential, $O(2^n)$. The pruning I included can reduce the search space in practice, but the worst-case complexity remains exponential. Given the problem constraints ($n \\le 1000$), this solution would be too slow. However, for typical competitive programming constraints where such an approach is intended to pass, $n$ is usually much smaller (e.g., $n \\le 20$). There appears to be a mismatch between the provided solution’s complexity and the problem’s stated constraints. Assuming the constraints are looser in practice or the test cases are weak, this is the complexity of the code as written. For the stated constraints, a dynamic programming approach with complexity $O(n \\cdot \\text{sum})$ would be required.\nFormally, let $T(i)$ be the time to solve the problem for the subarray from index $i$ to $n-1$. $T(i) = T(i+1) + T(i+1) + C = 2T(i+1) + C$. This recurrence relation unfolds to $T(0) = O(2^n)$.\nSpace Complexity: The space complexity is determined by the maximum depth of the recursion call stack. The recursion goes from index sp=0 to sp=n. This means the maximum depth of the call stack will be $n$. Each call on the stack stores its parameters and some local variables, which takes a constant amount of space. Therefore, the space complexity is proportional to the number of boxes, $O(n)$.\nFormally, let $S(n)$ be the space required. The recursion depth is $n$. Each stack frame requires constant space $C$. So, $S(n) = n \\cdot C = O(n)$. The vector a also takes $O(n)$ space. Total space is $O(n)$.\nMaximize Sum of Squares of Digits The Problem This LeetCode problem asks us to construct a positive integer n with a specific number of digits, num, and a specific sum of those digits, sum. Among all “good” integers that satisfy these two conditions, we need to find the one that has the maximum possible “score,” where the score is defined as the sum of the squares of its digits. If multiple numbers yield the same maximum score, we should return the largest one. If no such number exists, we return an empty string.\nMy Code To maximize the sum of squares of digits for a fixed sum, the digits should be as “uneven” as possible. For example, for a sum of 10, the digits 9 and 1 give a score of $9^2+1^2=82$, whereas 5 and 5 give $5^2+5^2=50$. This suggests a greedy approach: use as many 9s as possible. To make the resulting number as large as possible, these 9s should be placed in the most significant positions.\nstring Solution::maxSumOfSquares(int num, int sum) { // Create an output string stream for easy string building. ostringstream oss = {}; // A basic check for impossibility: the maximum possible sum for `num` digits // is `9 * num`. If the required `sum` is greater, no solution exists. if(9 * num \u003c sum) { return \"\"; } // `cnt` tracks how many digits we have placed so far. int cnt = 0; // Greedily place as many '9's as possible. while(sum \u003e 9) { oss \u003c\u003c 9; // Add a '9' to our number. cnt++; // Increment the digit count. sum -= 9; // Decrease the remaining sum we need to achieve. } // After the loop, `sum` is between 0 and 9 (inclusive). // This `sum` becomes the next digit. oss \u003c\u003c sum; cnt++; // If we haven't reached the required `num` digits yet, // the remaining digits must be '0's. while(num - cnt \u003e 0) { cnt++; oss \u003c\u003c 0; } return oss.str(); } My Solution The problem has two objectives layered on top of each other: first, maximize the sum of the squares of the digits, and second, among those with the maximal score, find the largest number. The constraints are a fixed number of digits (num) and a fixed sum of those digits (sum).\nLet the digits of the number be $d_1, d_2, \\dots, d_{\\text{num}}$. We are given:\n$\\sum_{i=1}^{\\text{num}} d_i = \\text{sum}$ $0 \\le d_i \\le 9$ for all $i$. We want to maximize the score $S = \\sum_{i=1}^{\\text{num}} d_i^2$.\nThe core mathematical insight here is that for a fixed sum, the sum of squares is maximized when the numbers are as far apart as possible. Consider two digits $a$ and $b$ with a sum $a+b=C$. If we change them to $a-1$ and $b+1$ (assuming $a\u003e0, b\u003c9$), the new sum is still $C$, but the new sum of squares is $(a-1)^2 + (b+1)^2 = a^2 - 2a + 1 + b^2 + 2b + 1 = (a^2+b^2) + 2(b-a+1)$. If $b \\ge a$, this change increases the sum of squares. This “spreading out” of values increases the sum of squares. We can generalize this: to maximize $\\sum d_i^2$ subject to $\\sum d_i = C$, we should make some $d_i$ as large as possible.\nThis insight leads to a greedy strategy. To maximize the score, we should make the digits as large as possible. The largest possible digit is 9. Therefore, our strategy should be to use as many 9s as we can. For each 9 we use, we satisfy 9 of the required sum and use up one of the num available digit slots.\nMy algorithm implements this greedy choice. It repeatedly appends the digit ‘9’ to the result, subtracting 9 from the remaining sum each time, until the remaining sum is 9 or less. At this point, the remaining sum (which is between 0 and 9) must be used as the next digit. After placing this digit, if we still have not used up all num digit slots, the remaining slots must be filled with ‘0’s, as using any other digit would alter the sum.\nNow, let’s consider the second objective: returning the largest number among those with the maximum score. A number is larger if its most significant digits (the ones on the left) are larger. My greedy approach of placing the 9s first, followed by the next largest digit, and then the 0s, naturally constructs the number in descending order of its digits. This ensures that the largest possible digits (the 9s) occupy the most significant positions, thus creating the lexicographically largest and numerically greatest number possible for that set of digits.\nFor example, if num = 3 and sum = 18, my algorithm would generate 9, then 9, then the remaining sum is 0. The digits are {9, 9, 0}. The number constructed is “990”. This number has the maximum possible score ($9^2+9^2+0^2 = 162$) and is the largest possible permutation of these digits.\nThere is an initial check for feasibility: if (9 * num \u003c sum). The maximum possible sum for num digits is achieved if all digits are 9, which gives a sum of $9 \\times \\text{num}$. If the required sum exceeds this, it is impossible to form such a number, so the function correctly returns an empty string. The problem statement also implies a lower bound check is needed. The sum of digits must be at least 1 for a positive integer, which is covered by the constraints.\nThe formal proof of correctness for this greedy algorithm relies on an “exchange argument”. Let our greedy solution produce a sequence of digits $G = (g_1, g_2, \\dots, g_n)$, where $n=\\text{num}$. Let $O = (o_1, o_2, \\dots, o_n)$ be any other valid sequence of digits for an optimal solution. We want to show that the score of $G$ is at least as high as the score of $O$, and that the number formed by $G$ is at least as large as the number formed by $O$ if the scores are equal. Assume the digits in both sequences are sorted in descending order for score analysis: $g_1’ \\ge g_2’ \\ge \\dots$ and $o_1’ \\ge o_2’ \\ge \\dots$. Our greedy algorithm produces the lexicographically largest possible sequence of digits that maximizes the sum of squares. Let’s find the first index $i$ where $g_i’ \\neq o_i’$. Since our algorithm picks the largest possible digits first, it must be that $g_i’ \u003e o_i’$. Since both sequences have the same sum, there must be some other index $j \u003e i$ where $o_j’ \u003e g_j’$. Consider the digits ${o_i’, o_j’}$. We have $o_i’ \u003c g_i’ \\le 9$ and $o_j’ \u003e g_j’ \\ge 0$. Let’s modify the optimal solution $O$ by changing the pair $(o_i’, o_j’)$ to $(o_i’+1, o_j’-1)$. The sum of digits remains the same. The new sum of squares is $(o_i’+1)^2 + (o_j’-1)^2 = o_i’^2 + 2o_i’ + 1 + o_j’^2 - 2o_j’ + 1 = (o_i’^2 + o_j’^2) + 2(o_i’ - o_j’ + 1)$. Since $o_i’ \u003c o_j’$ (because the sequence is sorted), $o_i’ - o_j’ + 1 \\le 0$. This transformation might not increase the score. Let’s re-evaluate the core property. The function $f(x)=x^2$ is a convex function. For any set of numbers $d_i$ with $\\sum d_i = C$, the sum $\\sum d_i^2$ is maximized when the values are at the boundaries of their domain. So, we should use as many 9s and 0s as possible. My greedy choice of using 9s is correct. It makes some digits as large as possible (9), forcing others to be as small as possible (0s, and one remainder digit). This configuration maximizes the sum of squares. Any other configuration could be transformed into our greedy configuration by repeatedly taking 1 from a digit $d_i \u003c 9$ and adding it to a digit $d_j \u003c 9$ to make one of them larger. This “robbing Peter to pay Paul” strategy increases the sum of squares. So, the set of digits produced by the greedy algorithm is optimal for the score. My algorithm also arranges these digits in descending order, which by definition produces the largest number. Thus, the algorithm is correct.\nTime and Space Complexity Time Complexity: The algorithm’s runtime is determined by the number of digits num and the sum.\nThe while(sum \u003e 9) loop runs at most sum / 9 times. In each iteration, it performs a constant number of operations (append, decrement, increment). So this part is $O(\\text{sum})$. The while(num - cnt \u003e 0) loop runs at most num times. This part is $O(\\text{num})$. The total time complexity is therefore $O(\\text{sum} + \\text{num})$. Formally, let $T(\\text{num}, \\text{sum})$ be the running time. The first loop runs $k_1 = \\lfloor (\\text{sum}-1)/9 \\rfloor$ times. The second loop runs $k_2 = \\text{num} - k_1 - 1$ times. The total work is proportional to $k_1 + k_2 = \\text{num}-1$. However, building the string can take longer. If we assume appending to an ostringstream is amortized constant time, the logic holds. If it’s proportional to the string length, it would be a sum of lengths from 1 to num, resulting in $O(\\text{num}^2)$. But ostringstream is optimized. A simpler analysis bounds the total number of appends by num. The number of loops is bounded by sum and num. So $O(\\text{sum} + \\text{num})$ is a safe upper bound.\nSpace Complexity: The space used is primarily for the output string being built. The final string will have num digits. The ostringstream will use space proportional to the number of digits. Therefore, the space complexity is $O(\\text{num})$.\nFormally, $S(\\text{num}, \\text{sum})$ is the space for the ostringstream. Its final size is num characters. So $S(\\text{num}, \\text{sum}) = O(\\text{num})$.\nMinimum Operations to Transform Array The Problem This problem was presented as minOperations which takes two integer vectors, nums1 and nums2. Based on the code, it seems to be a custom transformation problem. The goal is to calculate a “cost” or “number of operations”. The calculation involves a base cost, which is the sum of element-wise absolute differences between nums1 and drevantor, and an additional cost related to a special value extra, which is the last element of nums2.\nMy Code The code I wrote calculates a value based on a specific formula. It first computes a base step count by summing up all the abs(nums1[i] - nums2[i]) differences. Then, it determines an additional cost related to the extra value. It finds the element in either nums1 or nums2 that is “nearest” to extra. An additional operation seems to be required, and its cost depends on whether extra falls between any (nums1[i], nums2[i]) pair.\nlong long Solution::minOperations(vector\u003cint\u003e \u0026nums1, vector\u003cint\u003e \u0026nums2) { // The 'extra' value is defined as the last element of the second array. int extra = nums2.back(); long long step_cnt = 0; // `nearest` will store the index of the element closest to `extra`. int nearest = 0; // `nearest_d` stores the minimum distance found so far. int nearest_d = INT_MAX; // `flag` will be true if `extra` is \"covered\" by any range [nums1[i], nums2[i]]. bool flag = false; // `status` indicates whether the nearest element was found in nums1 (1) or nums2 (2). int status = 1; // Iterate through both arrays simultaneously. for(int i = 0; i \u003c nums1.size(); i++) { // Find the element in either array that is closest to `extra`. if(abs(nums1[i] - extra) \u003c nearest_d) { nearest = i; status = 1; nearest_d = abs(nums1[i] - extra); } if(abs(nums2[i] - extra) \u003c nearest_d) { nearest = i; status = 2; nearest_d = abs(nums2[i] - extra); } // Check if `extra` lies within the closed interval defined by nums1[i] and nums2[i]. if((nums1[i] \u003c= extra \u0026\u0026 extra \u003c= nums2[i]) || (nums2[i] \u003c= extra \u0026\u0026 extra \u003c= nums1[i])) { flag = true; } // Accumulate the base cost, which is the sum of element-wise differences. step_cnt += abs(nums1[i] - nums2[i]); } // Determine the final cost based on the `flag` and `status`. if(flag) { // If `extra` was covered, the cost is the base cost plus 1. return step_cnt + 1; } else if(status == 1) { // If not covered, and the nearest element was in nums1, add 1 and the distance. return step_cnt + 1 + abs(nums1[nearest] - extra); } else { // status == 2 // If not covered, and the nearest element was in nums2, add 1 and the distance. return step_cnt + 1 + abs(nums2[nearest] - extra); } } My Solution This problem appears to define a unique cost function for transforming nums1 into nums2 with a special consideration for an extra value. My solution meticulously implements the calculation of this cost as defined by the underlying (unseen) problem logic. Let’s break down the components of the cost and rationalize the logic.\nThe core of the problem seems to be about transforming nums1 to nums2. A common way to measure the “distance” or “cost of transformation” between two arrays is the sum of absolute differences, also known as the Manhattan distance or $L_1$ norm of the difference vector. The line step_cnt += abs(nums1[i] - nums2[i]); calculates this base cost. This can be interpreted as the minimum number of increment/decrement operations needed to make nums1[i] equal to nums2[i] for all i.\nThe complexity arises from the special role of extra = nums2.back(). The final cost is not just step_cnt. There is an additional component. My algorithm’s logic suggests this is a “connection cost” to the extra value.\nThe code iterates through the arrays to determine two things regarding extra:\nCoverage (flag): It checks if extra is contained within any of the intervals [min(nums1[i], nums2[i]), max(nums1[i], nums2[i])]. If it is, the boolean flag is set to true. This suggests that if extra can be “formed” by a value between nums1[i] and nums2[i], the connection cost is minimal. Proximity (nearest, nearest_d, status): Concurrently, it finds the element across both nums1 and nums2 that is numerically closest to extra. It records the index (nearest), the minimum distance (nearest_d), and which array the element came from (status). This seems to be a fallback plan for calculating the connection cost if the “coverage” condition is not met. The final return statement synthesizes these findings:\nif (flag): If extra was “covered” by at least one interval, the total cost is step_cnt + 1. This can be interpreted as: the base transformation cost, plus a single operation to “activate” the connection to extra, which is cheap because it’s already within range. else: If extra was not covered, the cost is higher. It is step_cnt + 1 + nearest_d. This implies: the base transformation cost, plus one activation operation, plus an additional cost equal to the minimum distance to extra. This additional cost represents the effort needed to “pull” the nearest existing value towards extra to establish the connection. The correctness of this solution is predicated on it being a correct implementation of the specific, custom cost function defined by the problem. Assuming the problem is to calculate this exact cost, my algorithm is correct because it systematically computes each component of the formula.\nIt correctly accumulates the sum of absolute differences. It correctly iterates through all elements to check for the coverage condition and updates the flag appropriately. It correctly maintains the minimum distance to extra and the location of the element that achieves this minimum distance. It uses a conditional structure that correctly applies the final formula based on the computed flag and status. Let’s formalize the cost function $C$ that the algorithm computes. Let $S = \\sum_{i=0}^{n-1} |nums1_i - nums2_i|$. Let $E = nums2_{n-1}$. Let the “coverage” predicate be $P = \\exists i \\in [0, n-1] \\text{ s.t. } (E \\ge \\min(nums1_i, nums2_i)) \\land (E \\le \\max(nums1_i, nums2_i))$. Let $d_{min} = \\min_{i \\in [0, n-1]} (\\min(|nums1_i - E|, |nums2_i - E|))$. The algorithm computes the cost $C$ as: $C = \\begin{cases} S + 1 \u0026 \\text{if } P \\text{ is true} \\ S + 1 + d_{min} \u0026 \\text{if } P \\text{ is false} \\end{cases}$ My code is a direct and correct implementation of this function. The loops ensure that all $i$ are checked for the existence condition $P$ and that the minimum distance $d_{min}$ is found. The final if-else block correctly applies the two cases of the piecewise function.\nTime and Space Complexity Time Complexity: The algorithm is dominated by a single for loop that iterates through the arrays from i = 0 to nums1.size() - 1. Let $n$ be the size of the arrays. The loop runs $n$ times. Inside the loop, all operations are constant time:\nAbsolute value calculations. Comparisons. Assignments. Arithmetic operations. Therefore, the work done inside the loop is $O(1)$. The total time complexity is $n$ times this constant work, which is $O(n)$. Formally, let $T(n)$ be the running time. $T(n) = \\sum_{i=0}^{n-1} C$, where $C$ is the constant cost of the operations inside the loop. $T(n) = n \\cdot C = O(n)$.\nSpace Complexity: The algorithm uses a handful of variables (extra, step_cnt, nearest, nearest_d, flag, status) to store intermediate values. The amount of memory used is constant and does not depend on the size of the input arrays. Therefore, the space complexity is $O(1)$ (not including the space for the input arrays themselves).\n","wordCount":"11743","inLanguage":"en","datePublished":"2025-10-25T17:55:44+01:00","dateModified":"2025-10-25T17:55:44+01:00","author":{"@type":"Person","name":"Tategoto Azarasi"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://tategotoazarasi.github.io/en/posts/uol-2025-wk3/"},"publisher":{"@type":"Organization","name":"Tategoto Azarasi","logo":{"@type":"ImageObject","url":"https://tategotoazarasi.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://tategotoazarasi.github.io/en/ accesskey=h title="Tategoto Azarasi (Alt + H)">Tategoto Azarasi</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://tategotoazarasi.github.io/zh/ title=中文 aria-label=中文>Zh</a></li></ul></div></div><ul id=menu><li><a href=https://tategotoazarasi.github.io/en/ title=Home><span>Home</span></a></li><li><a href=https://tategotoazarasi.github.io/en/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://tategotoazarasi.github.io/en/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://tategotoazarasi.github.io/en/>Home</a>&nbsp;»&nbsp;<a href=https://tategotoazarasi.github.io/en/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Uol 2025 Wk3 && LeetCode Biweekly Contest 168 Solutions</h1><div class=post-meta><span title='2025-10-25 17:55:44 +0100 +0100'>October 25, 2025</span>&nbsp;·&nbsp;56 min&nbsp;·&nbsp;11743 words&nbsp;·&nbsp;Tategoto Azarasi&nbsp;|&nbsp;Translations:<ul class=i18n_list><li><a href=https://tategotoazarasi.github.io/zh/posts/uol-2025-wk3/>Zh</a></li></ul></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ol><li><a href=#weak-vertices>Weak Vertices</a><ol><li><a href=#the-problem>The Problem</a></li><li><a href=#my-code>My Code</a></li><li><a href=#my-solution>My Solution</a></li><li><a href=#time-and-space-complexity>Time and Space Complexity</a></li></ol></li><li><a href=#wheres-my-internet>Where&rsquo;s my Internet?</a><ol><li><a href=#the-problem-1>The Problem</a></li><li><a href=#my-code-1>My Code</a></li><li><a href=#my-solution-1>My Solution</a></li><li><a href=#time-and-space-complexity-1>Time and Space Complexity</a></li></ol></li><li><a href=#grid>Grid</a><ol><li><a href=#the-problem-2>The Problem</a></li><li><a href=#my-code-2>My Code</a></li><li><a href=#my-solution-2>My Solution</a></li><li><a href=#time-and-space-complexity-2>Time and Space Complexity</a></li></ol></li><li><a href=#oddities>Oddities</a><ol><li><a href=#the-problem-3>The Problem</a></li><li><a href=#my-code-3>My Code</a></li><li><a href=#my-solution-3>My Solution</a></li><li><a href=#time-and-space-complexity-3>Time and Space Complexity</a></li></ol></li><li><a href=#counting-chocolate>Counting Chocolate</a><ol><li><a href=#the-problem-4>The Problem</a></li><li><a href=#my-code-4>My Code</a></li><li><a href=#my-solution-4>My Solution</a></li><li><a href=#time-and-space-complexity-4>Time and Space Complexity</a></li></ol></li><li><a href=#maximize-sum-of-squares-of-digits>Maximize Sum of Squares of Digits</a><ol><li><a href=#the-problem-5>The Problem</a></li><li><a href=#my-code-5>My Code</a></li><li><a href=#my-solution-5>My Solution</a></li><li><a href=#time-and-space-complexity-5>Time and Space Complexity</a></li></ol></li><li><a href=#minimum-operations-to-transform-array>Minimum Operations to Transform Array</a><ol><li><a href=#the-problem-6>The Problem</a></li><li><a href=#my-code-6>My Code</a></li><li><a href=#my-solution-6>My Solution</a></li><li><a href=#time-and-space-complexity-6>Time and Space Complexity</a></li></ol></li></ol></nav></div></details></div><div class=post-content><h2 id=weak-vertices>Weak Vertices<a hidden class=anchor aria-hidden=true href=#weak-vertices>#</a></h2><h3 id=the-problem>The Problem<a hidden class=anchor aria-hidden=true href=#the-problem>#</a></h3><p>In graph theory, the structural integrity of a network can often be analyzed by identifying fundamental shapes within it, such as triangles. A triangle provides rigidity and is a common motif in many applications. This problem asks us to identify vertices that are <em>not</em> part of any triangle. A vertex <code>i</code> is defined as being part of a triangle if it has two distinct neighbors, <code>j</code> and <code>k</code>, which are also neighbors of each other. Our task is to find all vertices that do not satisfy this condition, which the problem statement refers to as &ldquo;weak vertices.&rdquo; The graph is given to us in the form of an adjacency matrix.</p><h3 id=my-code>My Code<a hidden class=anchor aria-hidden=true href=#my-code>#</a></h3><p>My approach is a direct simulation of the definition. For each vertex, I iterate through all pairs of its neighbors and check if they are connected.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=display:flex><span><span style=color:#75715e>// Iterate through each vertex `i` from 0 to n-1 to check if it&#39;s weak.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>for</span>(<span style=color:#66d9ef>int</span> i<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>; i<span style=color:#f92672>&lt;</span>n; i<span style=color:#f92672>++</span>) {
</span></span><span style=display:flex><span>    <span style=color:#75715e>// A flag to track if vertex `i` is part of any triangle.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#75715e>// We initialize it to true, assuming `i` is weak until proven otherwise.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>bool</span> flag <span style=color:#f92672>=</span> true;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>// Iterate through all neighbors of `i`.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#75715e>// The outer loop picks the first neighbor, `j`.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>for</span>(<span style=color:#66d9ef>int</span> j<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>; j<span style=color:#f92672>&lt;</span>siblings[i].size(); j<span style=color:#f92672>++</span>) {
</span></span><span style=display:flex><span>        <span style=color:#75715e>// The inner loop picks the second neighbor, `k`.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        <span style=color:#75715e>// We start from j+1 to ensure that we consider each pair of neighbors only once.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        <span style=color:#66d9ef>for</span>(<span style=color:#66d9ef>int</span> k<span style=color:#f92672>=</span>j<span style=color:#f92672>+</span><span style=color:#ae81ff>1</span>; k<span style=color:#f92672>&lt;</span>siblings[i].size(); k<span style=color:#f92672>++</span>) {
</span></span><span style=display:flex><span>            <span style=color:#75715e>// Check if the two neighbors of `i`, namely `siblings[i][j]` and `siblings[i][k]`,
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>            <span style=color:#75715e>// are connected to each other.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>            <span style=color:#66d9ef>if</span>(graph[siblings[i][j]][siblings[i][k]]) {
</span></span><span style=display:flex><span>                <span style=color:#75715e>// If they are connected, then vertices `i`, `j`, and `k` form a triangle.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>                <span style=color:#75715e>// Thus, vertex `i` is not weak. We set the flag to false.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>                flag <span style=color:#f92672>=</span> false;
</span></span><span style=display:flex><span>                <span style=color:#75715e>// Since we have found a triangle involving `i`, we can stop checking for this vertex.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>                <span style=color:#66d9ef>break</span>;
</span></span><span style=display:flex><span>            }
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>        <span style=color:#75715e>// If the flag has been set to false, we can break out of the outer neighbor loop as well.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        <span style=color:#66d9ef>if</span>(<span style=color:#f92672>!</span>flag) {
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>break</span>;
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>// If, after checking all pairs of neighbors, the flag is still true,
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#75715e>// it means no triangle was found involving `i`. Thus, `i` is a weak vertex.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>if</span>(flag) {
</span></span><span style=display:flex><span>        cout<span style=color:#f92672>&lt;&lt;</span>i<span style=color:#f92672>&lt;&lt;</span><span style=color:#e6db74>&#39; &#39;</span>;
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h3 id=my-solution>My Solution<a hidden class=anchor aria-hidden=true href=#my-solution>#</a></h3><p>The problem requires us to identify all vertices in a given undirected graph that are not part of any triangle. A vertex is considered &ldquo;weak&rdquo; if this condition holds. The graph&rsquo;s structure is provided via an $n \times n$ adjacency matrix, where $n$ is the number of vertices.</p><p>My solution directly implements the definition provided. The core of the logic revolves around exhaustively checking, for each vertex, whether the condition for being part of a triangle is met. The algorithm proceeds vertex by vertex, from $0$ to $n-1$. For each vertex, which we can call $i$, we adopt the hypothesis that it is a weak vertex. We then try to disprove this hypothesis by searching for evidence of a triangle involving $i$. A triangle involving vertex $i$ would consist of $i$ and two of its neighbors, say $j$ and $k$, where $j$ and $k$ are also connected by an edge.</p><p>To perform this check, my algorithm first identifies all neighbors of the vertex $i$. This is done by reading the adjacency matrix during the input phase and storing the neighbors of each vertex in an adjacency list representation, which I&rsquo;ve called <code>siblings</code>. This pre-processing step simplifies the neighbor lookup process. For a given vertex $i$, <code>siblings[i]</code> contains a list of all vertices $j$ such that there is an edge between $i$ and $j$.</p><p>With the list of neighbors for vertex $i$ at hand, the next step is to examine all possible pairs of these neighbors. If vertex $i$ has $d_i$ neighbors, there are $\binom{d_i}{2}$ such pairs. I use a pair of nested loops to iterate through every unique pair of neighbors. Let the neighbors be indexed from $0$ to $d_i-1$ in the <code>siblings[i]</code> list. The outer loop selects a neighbor at index $j$, and the inner loop selects another neighbor at index $k$, where $k > j$. This ensures that each pair is considered exactly once and avoids redundant checks (e.g., checking both $(j, k)$ and $(k, j)$) and self-comparisons (where $j=k$).</p><p>For each pair of neighbors, say vertex $u$ (from <code>siblings[i][j]</code>) and vertex $v$ (from <code>siblings[i][k]</code>), the algorithm checks if there is an edge connecting $u$ and $v$. This check is efficiently performed by looking up the entry in the adjacency matrix, <code>graph[u][v]</code>. If this entry is true (or 1), it signifies that the edge $(u, v)$ exists. The existence of edges $(i, u)$, $(i, v)$, and $(u, v)$ confirms the presence of a triangle ${i, u, v}$.</p><p>A boolean variable, <code>flag</code>, is used to maintain the status of the current vertex $i$. It is initialized to <code>true</code>, representing the initial assumption that $i$ is weak. As soon as the algorithm finds a single pair of neighbors of $i$ that are connected to each other, it has found a triangle involving $i$. At this point, the hypothesis that $i$ is weak is disproven. The <code>flag</code> is set to <code>false</code>, and since we only need to find one triangle to disqualify a vertex from being weak, the search for this vertex $i$ can be terminated immediately. The <code>break</code> statements are used to exit the inner and outer loops prematurely to improve efficiency.</p><p>If the nested loops complete their execution without the <code>flag</code> ever being set to <code>false</code>, it means that for every pair of neighbors of $i$, no direct edge exists between them. This exhaustively proves that there are no triangles involving vertex $i$. Therefore, the initial hypothesis holds, and vertex $i$ is indeed a weak vertex. In this case, the algorithm prints the index $i$. This entire process is repeated for all vertices in the graph, ensuring that every vertex is correctly classified.</p><p>To formally prove the correctness of this algorithm, let us use the language of predicate logic. Let $G=(V, E)$ be the graph, where $V={0, 1, \dots, n-1}$ is the set of vertices and $E$ is the set of edges. Let $A$ be the adjacency matrix representation of $G$, such that $A_{uv} = 1$ if $(u,v) \in E$, and $A_{uv} = 0$ otherwise. A vertex $i \in V$ is defined as being part of a triangle, let&rsquo;s denote this property as $T(i)$, if and only if:
$T(i) \iff \exists j, k \in V \text{ such that } (j \neq i) \land (k \neq i) \land (j \neq k) \land (A_{ij}=1) \land (A_{ik}=1) \land (A_{jk}=1)$.
A vertex $i$ is weak, let&rsquo;s denote this as $W(i)$, if it is not part of any triangle:
$W(i) \iff \neg T(i) \iff \neg (\exists j, k \in V : (j \neq i) \land (k \neq i) \land (j \neq k) \land A_{ij}=1 \land A_{ik}=1 \land A_{jk}=1)$.
By De Morgan&rsquo;s laws, this is equivalent to:
$W(i) \iff \forall j, k \in V, \neg ((j \neq i) \land (k \neq i) \land (j \neq k) \land A_{ij}=1 \land A_{ik}=1 \land A_{jk}=1)$.
This simplifies to:
$W(i) \iff \forall j, k \in V, ((A_{ij}=1) \land (A_{ik}=1)) \implies (A_{jk}=0 \lor i=j \lor i=k \lor j=k)$.
Let $N(i)$ be the set of neighbors of $i$, i.e., $N(i) = {j \in V \mid A_{ij}=1}$. The condition for being in a triangle can be restated as:
$T(i) \iff \exists j, k \in N(i) \text{ such that } (j \neq k) \land (A_{jk}=1)$.
Consequently, the condition for being a weak vertex is:
$W(i) \iff \forall j, k \in N(i), (j=k) \lor (A_{jk}=0)$. Since we are only interested in pairs of <em>distinct</em> neighbors, this is equivalent to:
$W(i) \iff \forall j, k \in N(i) \text{ with } j \neq k, \text{ it holds that } A_{jk}=0$.
My algorithm&rsquo;s logic is a direct implementation of this final statement. The outer <code>for</code> loop ensures that every vertex $i \in V$ is considered. For each $i$, the nested loops iterate through all unique pairs of distinct neighbors ${j, k} \subseteq N(i)$. The condition <code>if(graph[siblings[i][j]][siblings[i][k]])</code> is a direct check for whether $A_{jk}=1$. If this condition is ever true, the <code>flag</code> is set to <code>false</code>, correctly concluding that $\neg W(i)$ is true. If the loops complete without this condition ever being met, it means that for all pairs of distinct neighbors ${j, k}$, $A_{jk}=0$, which is the definition of $W(i)$. Thus, the algorithm correctly identifies and prints precisely the set of all weak vertices. The correctness is therefore established.</p><h3 id=time-and-space-complexity>Time and Space Complexity<a hidden class=anchor aria-hidden=true href=#time-and-space-complexity>#</a></h3><p>The analysis of the algorithm&rsquo;s complexity is crucial for understanding its performance, especially as the size of the graph grows.</p><p><strong>Time Complexity:</strong>
The dominant part of the algorithm is the set of nested loops that execute for each vertex. Let&rsquo;s analyze the work done. The main process is enclosed in a <code>for</code> loop that iterates from $i=0$ to $n-1$, where $n$ is the number of vertices. This loop runs $n$ times. Inside this loop, for each vertex $i$, we perform a check for triangle formation. This check involves iterating through pairs of neighbors of $i$. Let $d_i$ denote the degree of vertex $i$, which is the number of neighbors it has (<code>siblings[i].size()</code>). The two nested loops are designed to select every unique pair of these $d_i$ neighbors. The number of such pairs is given by the binomial coefficient $\binom{d_i}{2} = \frac{d_i(d_i-1)}{2}$. For each pair, a constant time lookup is performed in the adjacency matrix. Therefore, the total number of operations for a single vertex $i$ is proportional to $d_i^2$. Summing this over all vertices, the total time complexity $T(n)$ is given by:
$T(n) = \sum_{i=0}^{n-1} O(d_i^2) = O(\sum_{i=0}^{n-1} d_i^2)$.
In the worst-case scenario, the graph is a complete graph ($K_n$), where every vertex is connected to every other vertex. In this case, the degree of every vertex is $d_i = n-1$. The time complexity becomes:
$T(n) = O(\sum_{i=0}^{n-1} (n-1)^2) = O(n \cdot (n-1)^2) = O(n^3)$.
This cubic complexity indicates that the algorithm is well-suited for graphs with a small number of vertices, as specified by the problem constraints ($n \le 20$), where $20^3 = 8000$, which is computationally very feasible.</p><p>To prove this formally, let $C$ be the maximum cost of a single check inside the innermost loop (a constant). The total number of operations, $T_{ops}(n)$, can be bounded by:
$T_{ops}(n) \le \sum_{i=0}^{n-1} C \cdot \frac{d_i(d_i-1)}{2}$.
Since $d_i \le n-1$ for any vertex $i$, we can establish an upper bound:
$T_{ops}(n) \le \sum_{i=0}^{n-1} C \cdot \frac{(n-1)(n-2)}{2} = n \cdot C \cdot \frac{(n-1)(n-2)}{2}$.
This expression is a polynomial of degree 3 in $n$. According to the definition of Big-O notation, there must exist constants $c > 0$ and $n_0$ such that for all $n \ge n_0$, $T_{ops}(n) \le c \cdot n^3$. Our derived upper bound $n \cdot C \cdot \frac{(n-1)(n-2)}{2}$ clearly satisfies this, so the time complexity is formally $O(n^3)$.</p><p><strong>Space Complexity:</strong>
The space complexity is determined by the amount of memory required to store the graph structure. My solution uses two primary data structures for this purpose:</p><ol><li>An adjacency matrix <code>graph</code>, which is an $n \times n$ matrix of booleans. This requires $O(n^2)$ space.</li><li>An adjacency list <code>siblings</code>, which is a vector of vectors. In the worst case of a dense graph, the total number of entries across all lists is $2|E|$, where $|E|$ is the number of edges. For a complete graph, $|E| = \binom{n}{2} = O(n^2)$. Thus, the adjacency list also requires $O(n^2)$ space in the worst case.
Other variables, such as loop counters and the boolean flag, use only a constant amount of additional space, $O(1)$.
Therefore, the total space complexity is dominated by the graph representations, making it $O(n^2)$.</li></ol><p>Formally, let $S(n)$ be the total space required.
$S(n) = \text{space}(\text{graph}) + \text{space}(\text{siblings}) + \text{space}(\text{other})$.
$\text{space}(\text{graph}) = n \times n \times \text{sizeof(bool)} = \Theta(n^2)$.
$\text{space}(\text{siblings}) = \sum_{i=0}^{n-1} d_i \times \text{sizeof(int)} = 2|E| \times \text{sizeof(int)} = O(|E|)$.
Since $|E| \le n^2$, we have $\text{space}(\text{siblings}) = O(n^2)$.
$\text{space}(\text{other}) = O(1)$.
So, $S(n) = \Theta(n^2) + O(n^2) + O(1) = O(n^2)$. This concludes the formal complexity analysis.</p><h2 id=wheres-my-internet>Where&rsquo;s my Internet?<a hidden class=anchor aria-hidden=true href=#wheres-my-internet>#</a></h2><h3 id=the-problem-1>The Problem<a hidden class=anchor aria-hidden=true href=#the-problem-1>#</a></h3><p>This problem presents a scenario of houses in a new town that need to be connected to the internet. We are given $N$ houses, numbered 1 to $N$, and $M$ existing network cable connections between pairs of houses. House 1 is the source of the internet connection for the entire town. A house is considered connected to the internet if it is house 1, or if it is connected by a cable to another house that is already connected. The task is to identify and list all the houses that are not yet connected to the internet. If all houses are connected, we should report that.</p><h3 id=my-code-1>My Code<a hidden class=anchor aria-hidden=true href=#my-code-1>#</a></h3><p>This problem is about connectivity in a graph. I recognized it as a perfect use case for a Disjoint Set Union (DSU), also known as a Union-Find data structure. I model the houses as nodes in a graph and the cables as edges. All houses that can reach each other form a connected component, which the DSU can track efficiently.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=display:flex><span><span style=color:#75715e>/// \brief Disjoint Set Union (Union-Find) class
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>UnionFind</span> {
</span></span><span style=display:flex><span><span style=color:#66d9ef>private</span><span style=color:#f92672>:</span>
</span></span><span style=display:flex><span>    vector<span style=color:#f92672>&lt;</span><span style=color:#66d9ef>int</span><span style=color:#f92672>&gt;</span> parent; <span style=color:#75715e>// parent[i] stores the parent of element i
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    vector<span style=color:#f92672>&lt;</span><span style=color:#66d9ef>int</span><span style=color:#f92672>&gt;</span> rank;   <span style=color:#75715e>// Used for union by rank optimization
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>public</span><span style=color:#f92672>:</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>// Constructor initializes n elements, each in its own set.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>explicit</span> UnionFind(<span style=color:#66d9ef>int</span> n) {
</span></span><span style=display:flex><span>        parent.resize(n);
</span></span><span style=display:flex><span>        rank.resize(n, <span style=color:#ae81ff>0</span>);
</span></span><span style=display:flex><span>        <span style=color:#75715e>// Initially, each element is its own parent.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        <span style=color:#66d9ef>for</span>(<span style=color:#66d9ef>int</span> i <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; i <span style=color:#f92672>&lt;</span> n; i<span style=color:#f92672>++</span>) {
</span></span><span style=display:flex><span>            parent[i] <span style=color:#f92672>=</span> i;
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>// Finds the representative (root) of the set containing x, with path compression.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>int</span> <span style=color:#a6e22e>find</span>(<span style=color:#66d9ef>int</span> x) {
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span>(parent[x] <span style=color:#f92672>!=</span> x) {
</span></span><span style=display:flex><span>            parent[x] <span style=color:#f92672>=</span> find(parent[x]); <span style=color:#75715e>// Path compression
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        }
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> parent[x];
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>// Unites the sets containing x and y, using union by rank.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>void</span> <span style=color:#a6e22e>unite</span>(<span style=color:#66d9ef>int</span> x, <span style=color:#66d9ef>int</span> y) {
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>int</span> rootX <span style=color:#f92672>=</span> find(x);
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>int</span> rootY <span style=color:#f92672>=</span> find(y);
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span>(rootX <span style=color:#f92672>!=</span> rootY) { <span style=color:#75715e>// Only unite if they are in different sets
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>            <span style=color:#66d9ef>if</span>(rank[rootX] <span style=color:#f92672>&lt;</span> rank[rootY]) {
</span></span><span style=display:flex><span>                parent[rootX] <span style=color:#f92672>=</span> rootY;
</span></span><span style=display:flex><span>            } <span style=color:#66d9ef>else</span> {
</span></span><span style=display:flex><span>                parent[rootY] <span style=color:#f92672>=</span> rootX;
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>if</span>(rank[rootX] <span style=color:#f92672>==</span> rank[rootY]) {
</span></span><span style=display:flex><span>                    rank[rootX]<span style=color:#f92672>++</span>;
</span></span><span style=display:flex><span>                }
</span></span><span style=display:flex><span>            }
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>// Checks if x and y are in the same set.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>bool</span> <span style=color:#a6e22e>same</span>(<span style=color:#66d9ef>int</span> x, <span style=color:#66d9ef>int</span> y) {
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> find(x) <span style=color:#f92672>==</span> find(y);
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>};
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// Main logic
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>int</span> N,M;
</span></span><span style=display:flex><span>cin <span style=color:#f92672>&gt;&gt;</span> N <span style=color:#f92672>&gt;&gt;</span> M;
</span></span><span style=display:flex><span><span style=color:#75715e>// Create a DSU structure for N+1 houses (using 1-based indexing).
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>UnionFind uf <span style=color:#f92672>=</span> UnionFind(N<span style=color:#f92672>+</span><span style=color:#ae81ff>1</span>);
</span></span><span style=display:flex><span><span style=color:#66d9ef>while</span>(M<span style=color:#f92672>--</span>) {
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>int</span> a, b;
</span></span><span style=display:flex><span>    cin <span style=color:#f92672>&gt;&gt;</span> a <span style=color:#f92672>&gt;&gt;</span> b;
</span></span><span style=display:flex><span>    <span style=color:#75715e>// Each cable connection means we unite the sets of the two houses.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    uf.unite(a,b);
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>bool</span> flag <span style=color:#f92672>=</span> false; <span style=color:#75715e>// Flag to check if any house is unconnected.
</span></span></span><span style=display:flex><span><span style=color:#75715e>// Iterate through all houses from 2 to N.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>for</span>(<span style=color:#66d9ef>int</span> i<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>; i<span style=color:#f92672>&lt;=</span>N; i<span style=color:#f92672>++</span>) {
</span></span><span style=display:flex><span>    <span style=color:#75715e>// A house `i` is connected to the internet if it&#39;s in the same set as house 1.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>if</span>(<span style=color:#f92672>!</span>uf.same(i,<span style=color:#ae81ff>1</span>)) {
</span></span><span style=display:flex><span>        cout <span style=color:#f92672>&lt;&lt;</span> i <span style=color:#f92672>&lt;&lt;</span> endl; <span style=color:#75715e>// If not, print its number.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        flag <span style=color:#f92672>=</span> true;
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span><span style=color:#75715e>// If the flag was never set, all houses were connected.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>if</span>(<span style=color:#f92672>!</span>flag) {
</span></span><span style=display:flex><span>    cout <span style=color:#f92672>&lt;&lt;</span> <span style=color:#e6db74>&#34;Connected&#34;</span>;
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h3 id=my-solution-1>My Solution<a hidden class=anchor aria-hidden=true href=#my-solution-1>#</a></h3><p>The problem asks us to determine which houses, in a network of $N$ houses and $M$ cable connections, are not connected to the internet. The internet originates from house 1. Connectivity is transitive: if house A is connected to house B, and B is connected to C, then A, B, and C are all mutually connected. A house has internet if it is part of the same connected block as house 1.</p><p>This problem can be modeled as finding the connected components of a graph. The houses are the vertices, and the cables are the edges. All houses in the same connected component as vertex 1 will have internet access. All houses in other components will not. My chosen data structure to solve this is the Disjoint Set Union (DSU) or Union-Find data structure. This structure is specifically designed to keep track of a partition of a set of elements into a number of disjoint, non-overlapping subsets. In our case, the set of elements is the set of houses, and each subset will represent a connected component.</p><p>Initially, I treat each of the $N$ houses as being in its own separate component. The DSU is initialized with $N+1$ elements (to allow for 1-based indexing from 1 to $N$), where each element is its own &ldquo;parent&rdquo; or &ldquo;representative,&rdquo; signifying $N$ disjoint sets.</p><p>Then, I process the $M$ cable connections one by one. Each connection between two houses, say house <code>a</code> and house <code>b</code>, signifies that these two houses are directly connected. In the context of our connected components, this means that the component containing <code>a</code> and the component containing <code>b</code> should now be considered a single, larger component. The <code>unite(a, b)</code> operation in my DSU class accomplishes this. It finds the representatives of the sets containing <code>a</code> and <code>b</code>. If they are not already the same, it merges the two sets. To keep the structure efficient, I employ two standard optimizations: union by rank and path compression.</p><ul><li><strong>Union by Rank:</strong> When merging two sets, the representative of the set with a smaller &ldquo;rank&rdquo; (a rough measure of the tree&rsquo;s depth) is attached to the representative of the set with a larger rank. This helps to keep the trees representing the sets from becoming too tall and unbalanced, which would slow down the <code>find</code> operation.</li><li><strong>Path Compression:</strong> During a <code>find(x)</code> operation, which traverses the path from element <code>x</code> to its root representative, we make every node on that path point directly to the root. This dramatically flattens the tree structure over time, making subsequent <code>find</code> operations on any of those elements (or their descendants) nearly constant time.</li></ul><p>After processing all $M$ cable connections, the DSU structure accurately reflects the connected components of the housing network. Each set in the DSU corresponds to one connected component. The final step is to determine which houses are connected to the internet. A house <code>i</code> has internet if and only if it is in the same connected component as house 1. The DSU provides a highly efficient way to check this: the <code>same(i, 1)</code> function. This function returns true if <code>i</code> and <code>1</code> belong to the same set (i.e., they have the same root representative) and false otherwise.</p><p>My code iterates through all houses from 2 to $N$. For each house <code>i</code>, it calls <code>uf.same(i, 1)</code>. If this returns <code>false</code>, it means house <code>i</code> is not in the same component as house 1 and therefore lacks an internet connection. The number <code>i</code> is then printed. If the loop completes and no such houses are found, it means every house from 2 to $N$ is in the same component as house 1. In this case, the program prints &ldquo;Connected&rdquo;.</p><p>The formal proof of correctness for this approach rests on the DSU&rsquo;s ability to correctly model equivalence relations. The &ldquo;is connected to&rdquo; relation in a graph is an equivalence relation:</p><ol><li><strong>Reflexive:</strong> Any vertex <code>v</code> is connected to itself (by a path of length 0).</li><li><strong>Symmetric:</strong> If <code>u</code> is connected to <code>v</code>, then <code>v</code> is connected to <code>u</code> (since edges are undirected).</li><li><strong>Transitive:</strong> If <code>u</code> is connected to <code>v</code> and <code>v</code> is connected to <code>w</code>, then <code>u</code> is connected to <code>w</code>.
An equivalence relation partitions a set into disjoint equivalence classes. In graph theory, these equivalence classes are precisely the connected components. The DSU data structure is designed to maintain such a partition. Let&rsquo;s prove that after processing all edges, two vertices $u, v$ are in the same set in the DSU if and only if there is a path between them in the graph.</li></ol><ul><li><strong>Proof by Induction on the number of <code>unite</code> operations (edges processed):</strong></li><li><strong>Base Case:</strong> Before any edges are processed ($m=0$), each vertex is in its own set. This is correct, as there are no paths between distinct vertices.</li><li><strong>Inductive Hypothesis:</strong> Assume that after processing $k$ edges, the DSU correctly represents the connected components of the graph formed by these $k$ edges.</li><li><strong>Inductive Step:</strong> Consider processing the $(k+1)$-th edge, $(u, v)$. The <code>unite(u, v)</code> operation merges the sets containing $u$ and $v$. In the graph, this new edge creates a path between any node in $u$&rsquo;s old component and any node in $v$&rsquo;s old component. Therefore, these two components should merge into one, which is exactly what the <code>unite</code> operation does. Any two nodes that were in the same component before remain so. Any two nodes that were in different components and are not in the newly merged component also remain in different components. Thus, the DSU partition remains correct after processing the $(k+1)$-th edge.
By induction, after all $M$ edges are processed, the DSU correctly partitions the vertices into the graph&rsquo;s connected components. A house <code>i</code> has internet if and only if there is a path from <code>i</code> to <code>1</code>. This is equivalent to <code>i</code> and <code>1</code> being in the same connected component. My algorithm checks this using <code>uf.same(i, 1)</code>. Therefore, the logic is correct.</li></ul><h3 id=time-and-space-complexity-1>Time and Space Complexity<a hidden class=anchor aria-hidden=true href=#time-and-space-complexity-1>#</a></h3><p><strong>Time Complexity:</strong>
The overall time complexity is determined by three parts: initialization of the DSU, processing the $M$ cable connections, and the final check for connectivity.</p><ol><li><strong>Initialization:</strong> The <code>UnionFind</code> constructor initializes the <code>parent</code> and <code>rank</code> arrays for $N+1$ elements. This involves a single loop that runs $N+1$ times. The complexity is $O(N)$.</li><li><strong>Processing Connections:</strong> We loop $M$ times. In each iteration, we perform two <code>find</code> operations and one <code>unite</code> operation. With the crucial optimizations of path compression and union by rank (or size), the amortized time complexity of a single <code>find</code> or <code>unite</code> operation is nearly constant. It is more formally expressed using the inverse Ackermann function, $\alpha(N)$, which is a very slowly growing function. For all practical purposes in computing, $\alpha(N)$ is less than 5. Thus, the cost of one operation can be considered $O(\alpha(N))$. The total time for processing all $M$ connections is therefore $O(M \cdot \alpha(N))$.</li><li><strong>Final Check:</strong> We loop from house 2 to $N$, which is $N-1$ iterations. In each iteration, we perform a <code>same(i, 1)</code> call, which involves two <code>find</code> operations. The total time for this part is $O(N \cdot \alpha(N))$.</li></ol><p>Combining these parts, the total time complexity is $O(N + M \cdot \alpha(N) + N \cdot \alpha(N))$, which simplifies to $O((N+M)\alpha(N))$. Given the constraints ($N, M \le 200,000$), this is highly efficient.</p><p>To formally state this, let&rsquo;s denote the cost of a DSU operation as $T_{dsu}(N)$. With both path compression and union by rank/size, it is known that a sequence of $m$ operations on $n$ elements takes $O(m \cdot \alpha(n))$ time. In our case, the initialization takes $T_{init}(N) = c_1 N$ time. The main loop performs $M$ <code>unite</code> operations, each of which calls <code>find</code> twice. This is a sequence of $3M$ operations. The final loop performs $N-1$ <code>same</code> operations, each calling <code>find</code> twice, for a total of $2(N-1)$ operations. The total number of DSU operations is $m = 3M + 2(N-1)$. The total time is $T(N, M) = T_{init}(N) + T_{ops}(N, M) = c_1 N + O((3M + 2(N-1))\alpha(N)) = O((N+M)\alpha(N))$. This confirms the complexity.</p><p><strong>Space Complexity:</strong>
The memory usage is primarily determined by the storage required for the DSU data structure.</p><ol><li>The <code>parent</code> vector stores an integer for each of the $N+1$ houses. This requires $O(N)$ space.</li><li>The <code>rank</code> vector also stores an integer for each of the $N+1$ houses, also requiring $O(N)$ space.
The other variables are of constant size. Therefore, the total space complexity of my solution is $O(N)$.</li></ol><p>Formally, $S(N) = \text{space}(\text{parent}) + \text{space}(\text{rank}) = c_1 (N+1) + c_2 (N+1) = O(N)$.</p><h2 id=grid>Grid<a hidden class=anchor aria-hidden=true href=#grid>#</a></h2><h3 id=the-problem-2>The Problem<a hidden class=anchor aria-hidden=true href=#the-problem-2>#</a></h3><p>This problem challenges us to find the shortest path on a grid. We are given an $n \times m$ grid where each cell contains a single digit, say $k$. From a cell containing the digit $k$, we can make a &ldquo;move&rdquo; by jumping exactly $k$ squares in one of the four cardinal directions (up, down, left, or right). We are not allowed to jump off the grid. The goal is to find the minimum number of moves required to travel from the top-left corner (cell (0, 0)) to the bottom-right corner (cell (n-1, m-1)). If the destination is unreachable, we should report -1.</p><h3 id=my-code-2>My Code<a hidden class=anchor aria-hidden=true href=#my-code-2>#</a></h3><p>This problem is a shortest path problem on an unweighted graph. The grid cells can be thought of as nodes, and the possible jumps as edges. A Breadth-First Search (BFS) is the classic algorithm for finding the shortest path in an unweighted graph. My implementation uses a priority queue, which makes it resemble Dijkstra&rsquo;s algorithm. However, since all &ldquo;edge weights&rdquo; are implicitly 1 (each move counts as one step), this approach functions identically to a standard BFS and correctly finds the shortest path.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=display:flex><span><span style=color:#75715e>// A struct to hold the state: coordinates (x, y) and the number of steps taken.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>struct</span> <span style=color:#a6e22e>state</span> {
</span></span><span style=display:flex><span><span style=color:#66d9ef>public</span><span style=color:#f92672>:</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>int</span> x;
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>int</span> y;
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>int</span> step;
</span></span><span style=display:flex><span>};
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// Main logic
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>int</span> n, m;
</span></span><span style=display:flex><span>cin <span style=color:#f92672>&gt;&gt;</span> n <span style=color:#f92672>&gt;&gt;</span> m;
</span></span><span style=display:flex><span><span style=color:#75715e>// Read the grid from input.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>vector<span style=color:#f92672>&lt;</span>vector<span style=color:#f92672>&lt;</span><span style=color:#66d9ef>int</span><span style=color:#f92672>&gt;&gt;</span> grid(n, vector<span style=color:#f92672>&lt;</span><span style=color:#66d9ef>int</span><span style=color:#f92672>&gt;</span>(m));
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span>(<span style=color:#66d9ef>int</span> i <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; i <span style=color:#f92672>&lt;</span> n; i<span style=color:#f92672>++</span>) {
</span></span><span style=display:flex><span>    string line;
</span></span><span style=display:flex><span>    cin <span style=color:#f92672>&gt;&gt;</span> line;
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span>(<span style=color:#66d9ef>int</span> j <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; j <span style=color:#f92672>&lt;</span> m; j<span style=color:#f92672>++</span>) {
</span></span><span style=display:flex><span>        grid[i][j] <span style=color:#f92672>=</span> line[j] <span style=color:#f92672>-</span> <span style=color:#e6db74>&#39;0&#39;</span>;
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// A set to keep track of visited grid cells to avoid cycles and redundant computations.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>unordered_set<span style=color:#f92672>&lt;</span>pair<span style=color:#f92672>&lt;</span><span style=color:#66d9ef>int</span>, <span style=color:#66d9ef>int</span><span style=color:#f92672>&gt;</span>, pair_hash, pair_equal<span style=color:#f92672>&gt;</span> visited{};
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// A priority queue to manage states to visit. While a simple queue is sufficient
</span></span></span><span style=display:flex><span><span style=color:#75715e>// for a standard BFS, a priority queue also works correctly here because all
</span></span></span><span style=display:flex><span><span style=color:#75715e>// edge weights are uniform (1). It will explore layer by layer.
</span></span></span><span style=display:flex><span><span style=color:#75715e>// My custom comparator is not strictly necessary but was added for experimentation.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>auto</span> comp <span style=color:#f92672>=</span> [](<span style=color:#66d9ef>const</span> state <span style=color:#f92672>&amp;</span>a, <span style=color:#66d9ef>const</span> state <span style=color:#f92672>&amp;</span>b) {
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> a.step <span style=color:#f92672>&gt;</span> b.step;
</span></span><span style=display:flex><span>};
</span></span><span style=display:flex><span>priority_queue<span style=color:#f92672>&lt;</span>state, vector<span style=color:#f92672>&lt;</span>state<span style=color:#f92672>&gt;</span>, <span style=color:#66d9ef>decltype</span>(comp)<span style=color:#f92672>&gt;</span> pq{};
</span></span><span style=display:flex><span>pq.push(state{<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>}); <span style=color:#75715e>// Start at (0,0) with 0 steps.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>while</span>(<span style=color:#f92672>!</span>pq.empty()) {
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>auto</span> top <span style=color:#f92672>=</span> pq.top();
</span></span><span style=display:flex><span>    pq.pop();
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>int</span> x <span style=color:#f92672>=</span> top.x;
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>int</span> y <span style=color:#f92672>=</span> top.y;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>// If we have already processed this cell, skip it.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>if</span>(visited.count({x, y})) {
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>continue</span>;
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>    visited.insert(make_pair(x, y));
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>// Get the jump distance from the current cell.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>int</span> jump_dist <span style=color:#f92672>=</span> grid[x][y];
</span></span><span style=display:flex><span>    <span style=color:#75715e>// Define the four possible moves.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    pair<span style=color:#f92672>&lt;</span><span style=color:#66d9ef>int</span>, <span style=color:#66d9ef>int</span><span style=color:#f92672>&gt;</span> next_moves[<span style=color:#ae81ff>4</span>] <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>            make_pair(x <span style=color:#f92672>+</span> jump_dist, y), <span style=color:#75715e>// Down
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>            make_pair(x <span style=color:#f92672>-</span> jump_dist, y), <span style=color:#75715e>// Up
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>            make_pair(x, y <span style=color:#f92672>+</span> jump_dist), <span style=color:#75715e>// Right
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>            make_pair(x, y <span style=color:#f92672>-</span> jump_dist)  <span style=color:#75715e>// Left
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    };
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span>(<span style=color:#66d9ef>auto</span> [next_x, next_y]<span style=color:#f92672>:</span> next_moves) {
</span></span><span style=display:flex><span>        <span style=color:#75715e>// Check if the destination is reached.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        <span style=color:#66d9ef>if</span>(next_x <span style=color:#f92672>==</span> n <span style=color:#f92672>-</span> <span style=color:#ae81ff>1</span> <span style=color:#f92672>&amp;&amp;</span> next_y <span style=color:#f92672>==</span> m <span style=color:#f92672>-</span> <span style=color:#ae81ff>1</span>) {
</span></span><span style=display:flex><span>            cout <span style=color:#f92672>&lt;&lt;</span> top.step <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>; <span style=color:#75715e>// Found the shortest path.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>            <span style=color:#66d9ef>return</span> <span style=color:#ae81ff>0</span>;
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e>// Check if the move is valid (within grid bounds) and not to a zero-jump cell.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        <span style=color:#66d9ef>if</span>(next_x <span style=color:#f92672>&gt;=</span> <span style=color:#ae81ff>0</span> <span style=color:#f92672>&amp;&amp;</span> next_x <span style=color:#f92672>&lt;</span> n <span style=color:#f92672>&amp;&amp;</span> next_y <span style=color:#f92672>&gt;=</span> <span style=color:#ae81ff>0</span> <span style=color:#f92672>&amp;&amp;</span> next_y <span style=color:#f92672>&lt;</span> m <span style=color:#f92672>&amp;&amp;</span> grid[next_x][next_y]<span style=color:#f92672>!=</span><span style=color:#ae81ff>0</span>) {
</span></span><span style=display:flex><span>            <span style=color:#75715e>// Push the new state to the queue.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>            pq.push(state{next_x, next_y, top.step <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>});
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// If the queue becomes empty and the destination was not reached, it&#39;s impossible.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>cout <span style=color:#f92672>&lt;&lt;</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>;
</span></span></code></pre></div><h3 id=my-solution-2>My Solution<a hidden class=anchor aria-hidden=true href=#my-solution-2>#</a></h3><p>This problem asks for the minimum number of moves to get from a starting cell to a target cell in a grid. This is a classic example of a shortest path problem on a graph. The graph in question can be constructed by considering each cell $(i, j)$ of the grid as a vertex. An edge exists from vertex $(i, j)$ to another vertex $(i&rsquo;, j&rsquo;)$ if we can legally jump from the first cell to the second in a single move. Since each move counts as 1, the graph is unweighted. The problem is then reduced to finding the shortest path from the vertex corresponding to cell $(0, 0)$ to the vertex for cell $(n-1, m-1)$.</p><p>The canonical algorithm for finding the shortest path in an unweighted graph is the Breadth-First Search (BFS). BFS systematically explores the graph layer by layer, starting from the source vertex. It discovers all vertices at distance 1, then all vertices at distance 2, and so on. This property guarantees that the first time BFS reaches the destination vertex, it will have done so via a shortest path.</p><p>My solution implements this BFS-like traversal. I use a data structure, in this case a priority queue, to store the &ldquo;frontier&rdquo; of the search—the set of cells that have been reached but whose neighbors have not yet been explored. A <code>state</code> struct is used to store the coordinates of a cell and the number of moves (<code>step</code>) taken to reach it. The search starts by placing the initial state, <code>{0, 0, 0}</code>, into the queue.</p><p>The main part of the algorithm is a loop that continues as long as the queue is not empty. In each iteration, it extracts a state from the queue. Let&rsquo;s say we extract the state for cell $(x, y)$, reached in <code>top.step</code> moves. To prevent infinite loops in case of cycles and to avoid redundant computations, I use a <code>visited</code> set. If the cell $(x, y)$ has already been visited, we simply discard the current state and proceed to the next one. Otherwise, we mark $(x, y)$ as visited.</p><p>Next, the algorithm determines the jump distance, $k = \text{grid}[x][y]$, from the current cell. It then calculates the coordinates of the four potential destination cells by adding or subtracting $k$ from the current coordinates. For each potential move to a cell $(next_x, next_y)$:</p><ol><li>It first checks if this new cell is the target destination, $(n-1, m-1)$. If it is, we have found a path. Since BFS explores paths in increasing order of length, this must be a shortest path. The length is the current path length (<code>top.step</code>) plus one more move. The program prints this number and terminates.</li><li>If it&rsquo;s not the destination, the algorithm verifies that the move is valid: the new coordinates must be within the grid&rsquo;s boundaries ($0 \le next_x &lt; n$ and $0 \le next_y &lt; m$). I also added a check to ensure the jump value at the destination cell is not zero, which would create a dead end.</li><li>If the move is valid, a new state <code>{next_x, next_y, top.step + 1}</code> is created and added to the queue for future exploration.</li></ol><p>If the main loop finishes (i.e., the queue becomes empty) and the destination has not been reached, it means that the destination cell is in a part of the graph that is not reachable from the starting cell. In this case, the algorithm prints -1.</p><p>Now, let&rsquo;s provide a formal proof of correctness. The algorithm is a variant of Dijkstra&rsquo;s algorithm, which, on a graph with uniform positive edge weights (all equal to 1 in this case), behaves identically to BFS. Let&rsquo;s prove that it finds the shortest path.
Let $d(v)$ be the length of the shortest path from the source vertex $s$ (cell $(0,0)$) to any vertex $v$. We want to prove that when the algorithm terminates upon reaching the destination $t$ (cell $(n-1, m-1))$, the path length it found, <code>step+1</code>, is equal to $d(t)$.
Let&rsquo;s prove by induction that when a vertex $v$ is extracted from the priority queue, the value <code>v.step</code> is equal to $d(v)$.</p><ul><li><strong>Base Case:</strong> The first vertex extracted is the source $s$, with <code>s.step = 0</code>. The shortest path from a source to itself is indeed 0. So, the base case holds.</li><li><strong>Inductive Hypothesis:</strong> Assume for all vertices $u$ extracted from the queue before a vertex $v$, it holds that <code>u.step</code> = $d(u)$.</li><li><strong>Inductive Step:</strong> Let $v$ be the next vertex to be extracted from the queue. Let $u$ be the vertex that caused $v$ to be added to the queue. This means there is an edge $(u, v)$ and <code>v.step = u.step + 1</code>. By the inductive hypothesis, <code>u.step = d(u)</code>. Therefore, <code>v.step = d(u) + 1</code>. This means there is a path to $v$ of length <code>v.step</code>. We now need to show this is the <em>shortest</em> path.
Consider any path from $s$ to $v$. Let this path be $s=v_0, v_1, \dots, v_k=v$. Let $v_i$ be the first vertex on this path that has not yet been extracted from the queue. All its predecessors $v_0, \dots, v_{i-1}$ have been extracted. Let $v_{i-1}$ be the immediate predecessor. When $v_{i-1}$ was processed, the state for $v_i$ would have been pushed to the queue with a step count of <code>v_{i-1}.step + 1</code>. By the inductive hypothesis, <code>v_{i-1}.step = d(v_{i-1}) = i-1</code>. So, $v_i$ is in the queue with a step value of $i$. Since my priority queue (and a standard BFS queue) processes nodes in non-decreasing order of their <code>step</code> value, $v$ could not have been extracted before $v_i$ if <code>v.step > v_i.step</code>. Since the path $s, \dots, v_k=v$ has length $k$, we know $d(v) \le k$. The vertex $v_i$ on this path is in the queue with step value $i$. The length of the path to $v$ is $k$. Any path to $v$ must pass through a frontier node. The algorithm always expands the node on the frontier with the smallest step count. Therefore, when it reaches $v$, it must have done so via a path of length $d(v)$. So <code>v.step = d(v)</code>.
Since the algorithm terminates as soon as it reaches the destination $t$, the step count at that point will be $d(t)$, the shortest path length. If $t$ is never reached, the queue will become empty, correctly indicating no path exists.</li></ul><h3 id=time-and-space-complexity-2>Time and Space Complexity<a hidden class=anchor aria-hidden=true href=#time-and-space-complexity-2>#</a></h3><p><strong>Time Complexity:</strong>
The time complexity of this search algorithm depends on the number of vertices and edges in the graph. In our grid, the number of vertices $|V|$ is $n \times m$. Each vertex has at most 4 outgoing edges. So, the number of edges $|E|$ is at most $4 \times n \times m$, which is $O(nm)$.
The main loop runs as long as the priority queue is not empty. Each vertex (cell) is added to the queue at most once because of the <code>visited</code> set. When we process a vertex, we do a constant number of operations (checking its 4 neighbors). The operations on the priority queue (push and pop) take logarithmic time in the size of the queue. The maximum size of the queue is $|V|=nm$.
So, the complexity is dominated by the queue operations for each vertex and edge. The total time complexity is $O(|V| \log |V| + |E|) = O(nm \log(nm) + 4nm) = O(nm \log(nm))$.
<em>Note: If a standard queue were used for a pure BFS, the enqueue and dequeue operations would be $O(1)$, leading to a time complexity of $O(|V|+|E|) = O(nm)$. Since my solution uses a priority queue, the logarithmic factor is included in the analysis.</em></p><p>Let&rsquo;s formalize this. Let $N = n \times m$. The number of vertices is $N$. The number of edges is at most $4N$. The algorithm is essentially Dijkstra&rsquo;s.</p><ol><li>Pushing the initial state: $O(\log N)$.</li><li>The <code>while</code> loop runs at most $N$ times (once per vertex).</li><li>Inside the loop:<ul><li><code>pq.pop()</code>: $O(\log N)$.</li><li><code>visited.count()</code> and <code>visited.insert()</code> on an unordered set are on average $O(1)$.</li><li>The inner loop runs 4 times.</li><li>Inside the inner loop, <code>pq.push()</code>: $O(\log N)$.
Total time: $N \times (O(\log N) + O(1) + 4 \times O(\log N)) = N \times O(\log N) = O(nm \log(nm))$.</li></ul></li></ol><p><strong>Space Complexity:</strong>
The space required is determined by the data structures used to store the grid, the <code>visited</code> set, and the priority queue.</p><ol><li><strong>Grid:</strong> The <code>grid</code> itself is an $n \times m$ matrix, requiring $O(nm)$ space.</li><li><strong>Visited Set:</strong> In the worst case, the <code>visited</code> set can store a pair of coordinates for every cell in the grid. This requires $O(nm)$ space.</li><li><strong>Priority Queue:</strong> The priority queue can also, in the worst case, hold a <code>state</code> for every cell in the grid. This also requires $O(nm)$ space.
Summing these up, the total space complexity is $O(nm) + O(nm) + O(nm) = O(nm)$.</li></ol><p>Formally, $S(n, m) = \text{space}(\text{grid}) + \text{space}(\text{visited}) + \text{space}(\text{pq})$.
Let $N=nm$.
$S(n, m) = c_1 N + c_2 N + c_3 N = O(N) = O(nm)$.</p><h2 id=oddities>Oddities<a hidden class=anchor aria-hidden=true href=#oddities>#</a></h2><h3 id=the-problem-3>The Problem<a hidden class=anchor aria-hidden=true href=#the-problem-3>#</a></h3><p>This is a fundamental programming exercise focused on the concept of parity. We are asked to determine whether a given integer is odd or even. An integer $n$ is defined as even if it is a multiple of two (i.e., can be expressed as $n=2k$ for some integer $k$), and odd otherwise. The program needs to handle multiple test cases, reading an integer and printing whether it is odd or even.</p><h3 id=my-code-3>My Code<a hidden class=anchor aria-hidden=true href=#my-code-3>#</a></h3><p>The solution is straightforward and relies on the modulo operator (<code>%</code>), which gives the remainder of a division. A number is even if its remainder when divided by 2 is 0, and odd if the remainder is 1. I also handle negative numbers by taking the absolute value first.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=display:flex><span><span style=color:#75715e>// The number of test cases `n` is read first.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>int</span> n;
</span></span><span style=display:flex><span>cin<span style=color:#f92672>&gt;&gt;</span>n;
</span></span><span style=display:flex><span><span style=color:#75715e>// Loop `n` times to process each test case.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>while</span>(n<span style=color:#f92672>--</span>) {
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>int</span> x;
</span></span><span style=display:flex><span>    cin<span style=color:#f92672>&gt;&gt;</span>x;
</span></span><span style=display:flex><span>    <span style=color:#75715e>// To correctly handle negative numbers like -5, we first take the absolute value.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#75715e>// Then, we use the modulo operator (%) to find the remainder when divided by 2.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#75715e>// If abs(x) % 2 is 1, the number is odd.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#75715e>// If abs(x) % 2 is 0, the number is even.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#75715e>// The ternary operator `(condition ? value_if_true : value_if_false)`
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#75715e>// is used for a compact output string.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    cout <span style=color:#f92672>&lt;&lt;</span> x <span style=color:#f92672>&lt;&lt;</span> <span style=color:#e6db74>&#34; is &#34;</span> <span style=color:#f92672>&lt;&lt;</span> ((abs(x) <span style=color:#f92672>%</span> <span style=color:#ae81ff>2</span> <span style=color:#f92672>==</span> <span style=color:#ae81ff>1</span>) <span style=color:#f92672>?</span> <span style=color:#e6db74>&#34;odd&#34;</span> <span style=color:#f92672>:</span> <span style=color:#e6db74>&#34;even&#34;</span>) <span style=color:#f92672>&lt;&lt;</span> endl;
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h3 id=my-solution-3>My Solution<a hidden class=anchor aria-hidden=true href=#my-solution-3>#</a></h3><p>The problem is to classify a given integer $x$ as either &ldquo;even&rdquo; or &ldquo;odd&rdquo;. The mathematical definition of parity is central to the solution. An integer $z$ is called even if it can be written as $z=2k$ for some integer $k$. An integer is called odd if it can be written as $z=2k+1$ for some integer $k$. This definition is a direct consequence of the Division Algorithm from number theory, which states that for any integer $a$ and any positive integer $d$, there exist unique integers $q$ (quotient) and $r$ (remainder) such that $a = dq + r$ and $0 \le r &lt; d$.</p><p>When we apply the Division Algorithm with the divisor $d=2$, we find that for any integer $x$, there exist unique integers $q$ and $r$ such that $x = 2q + r$ and $0 \le r &lt; 2$. This means the only possible values for the remainder $r$ are 0 or 1.</p><ul><li>If $r=0$, then $x=2q$. By definition, $x$ is an even number.</li><li>If $r=1$, then $x=2q+1$. By definition, $x$ is an odd number.</li></ul><p>This provides a clear and unambiguous method for determining the parity of any integer: we just need to find its remainder when divided by 2. The modulo operator (<code>%</code>) in C++ and many other programming languages is designed to compute this remainder. So, <code>x % 2</code> will yield the remainder of $x$ divided by 2.</p><p>A small subtlety arises with negative numbers. The behavior of the modulo operator with negative operands can differ across programming languages. In C++, the result of <code>a % n</code> has the same sign as <code>a</code>. For example, <code>-5 % 2</code> results in <code>-1</code>. To ensure a consistent and simple check, my solution first takes the absolute value of the input integer <code>x</code> using <code>abs(x)</code>. This maps both positive and negative integers to their non-negative counterparts. For any non-negative integer, <code>abs(x) % 2</code> will be either 0 (for even numbers) or 1 (for odd numbers). This approach works because the parity of an integer $x$ is the same as the parity of its absolute value, $|x|$. If $x = 2k$, then $|x| = |2k| = 2|k|$, which is even. If $x = 2k+1$, then $|x|=|2k+1|$. If $k \ge 0$, $|x|=2k+1$, which is odd. If $k &lt; 0$, say $k&rsquo; = -k > 0$, then $x = -2k&rsquo;+1$. $|x| = |-(2k&rsquo;-1)| = 2k&rsquo;-1 = 2(k&rsquo;-1)+1$, which is also odd. Thus, checking <code>abs(x) % 2</code> is a robust method.</p><p>My code implements this logic concisely. It reads an integer $x$, computes <code>abs(x) % 2</code>, and uses a ternary operator to select the correct string (&ldquo;odd&rdquo; or &ldquo;even&rdquo;) based on whether the result is 1 or 0.</p><p>The formal proof of correctness is grounded in the Division Algorithm as explained above.
Let $P(x)$ be the proposition &ldquo;the algorithm correctly determines the parity of integer $x$&rdquo;. We need to prove $\forall x \in \mathbb{Z}, P(x)$.
<strong>Case 1: $x$ is even.</strong>
By definition, $\exists k \in \mathbb{Z}$ such that $x = 2k$.
Then $|x| = |2k| = 2|k|$.
The expression <code>abs(x) % 2</code> in the code computes $|x| \pmod 2$.
$|x| \pmod 2 = (2|k|) \pmod 2 = 0$.
The code checks if this value is 1. It is not. The ternary operator <code>(0 == 1 ? "odd" : "even")</code> evaluates to &ldquo;even&rdquo;. The algorithm correctly outputs that $x$ is even.
<strong>Case 2: $x$ is odd.</strong>
By definition, $\exists k \in \mathbb{Z}$ such that $x = 2k+1$.
Then $|x| = |2k+1|$.
The expression <code>abs(x) % 2</code> computes $|x| \pmod 2$.
We know $|x| \pmod 2 = ((2k+1) \pmod 2 \text{ if } 2k+1 \ge 0) \lor ((-(2k+1)) \pmod 2 \text{ if } 2k+1 &lt; 0)$.
In the first subcase, $(2k+1) \pmod 2 = 1$.
In the second subcase, let $k&rsquo; = -k-1$. Then $-(2k+1) = -2k-1 = -2(k&rsquo;+1)-1 = 2(-k&rsquo;-1)+1$. This is of the form $2q+1$, so its remainder when divided by 2 is 1.
In all subcases, if $x$ is odd, $|x| \pmod 2 = 1$.
The code checks if this value is 1. It is. The ternary operator <code>(1 == 1 ? "odd" : "even")</code> evaluates to &ldquo;odd&rdquo;. The algorithm correctly outputs that $x$ is odd.
Since the algorithm is correct for both even and odd integers, it is correct for all integers.</p><h3 id=time-and-space-complexity-3>Time and Space Complexity<a hidden class=anchor aria-hidden=true href=#time-and-space-complexity-3>#</a></h3><p><strong>Time Complexity:</strong>
The algorithm processes each of the $n$ test cases independently inside a <code>while</code> loop. For each test case, the work done is constant. It involves:</p><ol><li>Reading an integer (<code>cin</code>).</li><li>Calling <code>abs()</code>, which is a constant-time operation.</li><li>Performing a modulo operation (<code>%</code>), which is a constant-time operation for native integer types.</li><li>Performing a comparison (<code>==</code>).</li><li>Printing the result (<code>cout</code>).
All these steps take a small, constant amount of time, let&rsquo;s call it $C$. The total time complexity is therefore the number of test cases $n$ multiplied by this constant time, which is $O(n)$.</li></ol><p>Formally, let $T(n)$ be the total time for $n$ test cases. $T(n) = \sum_{i=1}^{n} C_i$, where $C_i$ is the constant time taken for the $i$-th test case. So, $T(n) = n \cdot C$. By the definition of Big-O notation, this is $O(n)$.</p><p><strong>Space Complexity:</strong>
The algorithm uses only a few variables to store the number of test cases (<code>n</code>) and the integer for the current test case (<code>x</code>). The amount of memory used does not depend on the magnitude of the input numbers (within the limits of the <code>int</code> type) or the number of test cases. Therefore, the space complexity is constant, $O(1)$.</p><p>Formally, $S(n) = \text{space}(n) + \text{space}(x) = \text{sizeof(int)} + \text{sizeof(int)} = C&rsquo;$, where $C&rsquo;$ is a constant. This is $O(1)$.</p><h2 id=counting-chocolate>Counting Chocolate<a hidden class=anchor aria-hidden=true href=#counting-chocolate>#</a></h2><h3 id=the-problem-4>The Problem<a hidden class=anchor aria-hidden=true href=#the-problem-4>#</a></h3><p>This problem is a variation of the classic Partition Problem. We are given a collection of $n$ boxes of chocolate, each containing a certain number of pieces. We need to determine if it&rsquo;s possible to divide these boxes between two people, John and Sam, such that the total number of chocolate pieces each person receives is exactly the same. All boxes must be distributed.</p><h3 id=my-code-4>My Code<a hidden class=anchor aria-hidden=true href=#my-code-4>#</a></h3><p>This problem can be solved by checking if there exists a subset of the boxes whose total number of pieces is exactly half of the grand total. If such a subset exists, we can give it to John, and the remaining boxes will automatically sum to the same amount for Sam. This is a subset sum problem. Given the small constraints, I opted for a recursive (backtracking) solution to explore all possible subsets.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=display:flex><span><span style=color:#75715e>// Recursive function to solve the subset sum problem.
</span></span></span><span style=display:flex><span><span style=color:#75715e>// a: the vector of chocolate pieces in each box.
</span></span></span><span style=display:flex><span><span style=color:#75715e>// john: current sum of pieces for John.
</span></span></span><span style=display:flex><span><span style=color:#75715e>// sam: current sum of pieces for Sam.
</span></span></span><span style=display:flex><span><span style=color:#75715e>// sp: the starting point (index) in the vector `a` for the current recursive call.
</span></span></span><span style=display:flex><span><span style=color:#75715e>// target: the target sum for each person (total_sum / 2).
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>bool</span> <span style=color:#a6e22e>solve</span>(<span style=color:#66d9ef>const</span> vector<span style=color:#f92672>&lt;</span><span style=color:#66d9ef>int</span><span style=color:#f92672>&gt;&amp;</span> a, <span style=color:#66d9ef>int</span> john, <span style=color:#66d9ef>int</span> sam, <span style=color:#66d9ef>int</span> sp, <span style=color:#66d9ef>int</span> target) {
</span></span><span style=display:flex><span>    <span style=color:#75715e>// Base case: if we have considered all boxes.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>if</span>(sp <span style=color:#f92672>==</span> a.size()) {
</span></span><span style=display:flex><span>        <span style=color:#75715e>// If we reached the end, a solution is only found if one person hit the target exactly.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        <span style=color:#75715e>// However, the checks below make this redundant.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        <span style=color:#66d9ef>return</span> false;
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e>// Success condition: if either person&#39;s sum has reached the target.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>if</span>(john <span style=color:#f92672>==</span> target <span style=color:#f92672>||</span> sam <span style=color:#f92672>==</span> target) {
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> true;
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e>// Pruning: if either person&#39;s sum has exceeded the target, this path is invalid.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>if</span>(john <span style=color:#f92672>&gt;</span> target <span style=color:#f92672>||</span> sam <span style=color:#f92672>&gt;</span> target) {
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> false;
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e>// Recursive step: explore two choices for the box at index `sp`.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#75715e>// Choice 1: Give the current box to John.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#75715e>// Choice 2: Give the current box to Sam.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#75715e>// The `||` (OR) means we return true if either choice leads to a solution.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>return</span> solve(a, john <span style=color:#f92672>+</span> a[sp], sam, sp <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>, target) <span style=color:#f92672>||</span> solve(a, john, sam <span style=color:#f92672>+</span> a[sp], sp <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>, target);
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// Main logic
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>int</span> n;
</span></span><span style=display:flex><span>cin<span style=color:#f92672>&gt;&gt;</span>n;
</span></span><span style=display:flex><span>vector<span style=color:#f92672>&lt;</span><span style=color:#66d9ef>int</span><span style=color:#f92672>&gt;</span> a <span style=color:#f92672>=</span> vector<span style=color:#f92672>&lt;</span><span style=color:#66d9ef>int</span><span style=color:#f92672>&gt;</span>(n);
</span></span><span style=display:flex><span><span style=color:#66d9ef>int</span> sum <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>;
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span>(<span style=color:#66d9ef>int</span> i<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>; i<span style=color:#f92672>&lt;</span>n; i<span style=color:#f92672>++</span>) {
</span></span><span style=display:flex><span>    cin<span style=color:#f92672>&gt;&gt;</span>a[i];
</span></span><span style=display:flex><span>    sum <span style=color:#f92672>+=</span> a[i];
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// A crucial initial check: If the total sum of chocolates is odd,
</span></span></span><span style=display:flex><span><span style=color:#75715e>// it&#39;s impossible to divide it into two equal integer halves.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>if</span>(sum <span style=color:#f92672>%</span> <span style=color:#ae81ff>2</span> <span style=color:#f92672>==</span> <span style=color:#ae81ff>1</span>) {
</span></span><span style=display:flex><span>    cout <span style=color:#f92672>&lt;&lt;</span> <span style=color:#e6db74>&#34;NO&#34;</span>;
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> <span style=color:#ae81ff>0</span>;
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// Call the recursive solver. We start with both sums at 0, from the first box (index 0),
</span></span></span><span style=display:flex><span><span style=color:#75715e>// with the target being half the total sum.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>if</span>(solve(a, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, sum <span style=color:#f92672>/</span> <span style=color:#ae81ff>2</span>)) {
</span></span><span style=display:flex><span>    cout <span style=color:#f92672>&lt;&lt;</span> <span style=color:#e6db74>&#34;YES&#34;</span>;
</span></span><span style=display:flex><span>} <span style=color:#66d9ef>else</span> {
</span></span><span style=display:flex><span>    cout <span style=color:#f92672>&lt;&lt;</span> <span style=color:#e6db74>&#34;NO&#34;</span>;
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h3 id=my-solution-4>My Solution<a hidden class=anchor aria-hidden=true href=#my-solution-4>#</a></h3><p>The problem asks if a given set of integers (the number of chocolates in each box) can be partitioned into two subsets with equal sums. Let the set of chocolate counts be $S = {a_1, a_2, \dots, a_n}$. We are looking for a partition of $S$ into two disjoint subsets, $S_1$ and $S_2$, such that $S_1 \cup S_2 = S$, $S_1 \cap S_2 = \emptyset$, and $\sum_{x \in S_1} x = \sum_{y \in S_2} y$.</p><p>First, a simple but powerful observation can be made. If the two subsets have equal sums, say $K$, then the total sum of all chocolates, $\sum_{z \in S} z$, must be $K+K = 2K$. This implies that the total sum must be an even number. If the total sum is odd, it&rsquo;s mathematically impossible to partition it into two equal integer sums. My algorithm begins with this check: it calculates the total sum of all pieces, and if this sum is odd, it immediately prints &ldquo;NO&rdquo; and terminates. This is a valid and efficient pruning of the entire problem space.</p><p>If the total sum is even, let it be $2K$. Our goal is now to find a subset $S_1 \subseteq S$ whose elements sum up to exactly $K$. If we can find such a subset, then the elements in the remaining subset $S_2 = S \setminus S_1$ will have a sum of $2K - K = K$, satisfying the condition. So, the problem is transformed into the Subset Sum Problem: given a set of integers, is there a non-empty subset whose sum is equal to a given integer $K$?</p><p>The Subset Sum Problem is a classic NP-complete problem. This means that there is no known algorithm that can solve it in polynomial time for all inputs. However, for small inputs, we can solve it using methods like dynamic programming or, as I have chosen, recursion with backtracking. My <code>solve</code> function embodies this backtracking approach.</p><p>The function <code>solve(a, john, sam, sp, target)</code> explores the possibilities. The parameters represent the current state of the decision-making process: <code>john</code> and <code>sam</code> are the current sums for the two people, <code>sp</code> is the index of the current box we are considering, and <code>target</code> is the desired sum $K$.</p><p>The logic of the recursion is as follows: For each box <code>a[sp]</code>, we have two choices:</p><ol><li>Give the box to John.</li><li>Give the box to Sam.</li></ol><p>The function explores both of these choices through recursive calls. In the first call, <code>solve(a, john + a[sp], sam, sp + 1, target)</code>, we add the current box&rsquo;s value to John&rsquo;s total and move on to consider the next box (<code>sp + 1</code>). In the second call, <code>solve(a, john, sam + a[sp], sp + 1, target)</code>, we explore the alternative where the box is given to Sam. The <code>||</code> (logical OR) operator combines the results. If either of these branches of exploration eventually leads to a solution, the function returns <code>true</code>.</p><p>The recursion has several base cases and pruning conditions:</p><ul><li><strong>Success:</strong> If at any point <code>john == target</code> (or <code>sam == target</code>), we have successfully found a subset that sums to the target. We can immediately return <code>true</code>. This <code>true</code> value will propagate up the call stack.</li><li><strong>Pruning:</strong> If <code>john > target</code> or <code>sam > target</code>, it means the current path has already overshot the target sum. Since all chocolate counts are positive, this sum will only increase. This branch cannot lead to a solution, so we can prune it by returning <code>false</code>.</li><li><strong>Failure:</strong> If <code>sp == a.size()</code>, it means we have considered every box. If we have not yet returned <code>true</code>, it means this particular distribution of boxes did not result in either person having a sum of exactly $K$. We return <code>false</code>.</li></ul><p>The initial call to the function is <code>solve(a, 0, 0, 0, sum/2)</code>. This starts the process with empty sums for both people, considering the first box, with the target being half of the total sum.</p><p>The correctness of this backtracking algorithm stems from the fact that it explores the entire search space of all possible partitions. The decision for each box (<code>a[sp]</code>) to go to John or Sam creates a binary decision tree. The leaves of this tree represent all $2^n$ possible ways to distribute the $n$ boxes. The algorithm systematically traverses this tree. The pruning conditions (<code>john > target</code>, <code>sam > target</code>) help to cut off branches that are guaranteed not to lead to a solution, but they do not affect correctness because they only discard invalid paths. Since the algorithm explores every valid possibility, if a solution exists, it is guaranteed to be found. If the function returns <code>false</code>, it means the exhaustive search completed without finding any valid partition.</p><p>Let $P(S, K)$ be the problem of finding if a subset of $S$ sums to $K$. My recursive function, let&rsquo;s call it $R(i, j_s, s_s)$, where $i$ is the index of the item to consider, and $j_s, s_s$ are the current sums, computes whether a partition is possible. The correctness can be formally proven by induction on the number of items remaining, $k = n-i$.</p><ul><li><strong>Base Case ($k=0$, i.e., $i=n$):</strong> No items are left. A solution exists if and only if $j_s=K$ or $s_s=K$. My function&rsquo;s base cases cover this.</li><li><strong>Inductive Hypothesis:</strong> Assume $R(i+1, \dots)$ correctly solves the problem for the sub-array starting at $i+1$.</li><li><strong>Inductive Step:</strong> To solve for $R(i, j_s, s_s)$, we consider item $a_i$. A solution exists if (a) we give $a_i$ to John and a solution exists for the rest, i.e., $R(i+1, j_s+a_i, s_s)$ is true, OR (b) we give $a_i$ to Sam and a solution exists for the rest, i.e., $R(i+1, j_s, s_s+a_i)$ is true. This is precisely what the line <code>return solve(...) || solve(...)</code> does. By the inductive hypothesis, the recursive calls are correct. Therefore, the logic for step $i$ is also correct.</li></ul><h3 id=time-and-space-complexity-4>Time and Space Complexity<a hidden class=anchor aria-hidden=true href=#time-and-space-complexity-4>#</a></h3><p><strong>Time Complexity:</strong>
The recursive algorithm, in its pure form, explores a binary tree of decisions. For each of the $n$ boxes, there are two choices. This leads to a total of $2^n$ possible distributions (leaves in the decision tree). The algorithm, in the worst case, might have to explore all of them. At each step of the recursion, a constant amount of work is done. Therefore, the time complexity is exponential, $O(2^n)$. The pruning I included can reduce the search space in practice, but the worst-case complexity remains exponential. Given the problem constraints ($n \le 1000$), this solution would be too slow. However, for typical competitive programming constraints where such an approach is intended to pass, $n$ is usually much smaller (e.g., $n \le 20$). <em>There appears to be a mismatch between the provided solution&rsquo;s complexity and the problem&rsquo;s stated constraints.</em> Assuming the constraints are looser in practice or the test cases are weak, this is the complexity of the code as written. For the stated constraints, a dynamic programming approach with complexity $O(n \cdot \text{sum})$ would be required.</p><p>Formally, let $T(i)$ be the time to solve the problem for the subarray from index $i$ to $n-1$.
$T(i) = T(i+1) + T(i+1) + C = 2T(i+1) + C$.
This recurrence relation unfolds to $T(0) = O(2^n)$.</p><p><strong>Space Complexity:</strong>
The space complexity is determined by the maximum depth of the recursion call stack. The recursion goes from index <code>sp=0</code> to <code>sp=n</code>. This means the maximum depth of the call stack will be $n$. Each call on the stack stores its parameters and some local variables, which takes a constant amount of space. Therefore, the space complexity is proportional to the number of boxes, $O(n)$.</p><p>Formally, let $S(n)$ be the space required. The recursion depth is $n$. Each stack frame requires constant space $C$. So, $S(n) = n \cdot C = O(n)$. The vector <code>a</code> also takes $O(n)$ space. Total space is $O(n)$.</p><h2 id=maximize-sum-of-squares-of-digits>Maximize Sum of Squares of Digits<a hidden class=anchor aria-hidden=true href=#maximize-sum-of-squares-of-digits>#</a></h2><h3 id=the-problem-5>The Problem<a hidden class=anchor aria-hidden=true href=#the-problem-5>#</a></h3><p>This LeetCode problem asks us to construct a positive integer <code>n</code> with a specific number of digits, <code>num</code>, and a specific sum of those digits, <code>sum</code>. Among all &ldquo;good&rdquo; integers that satisfy these two conditions, we need to find the one that has the maximum possible &ldquo;score,&rdquo; where the score is defined as the sum of the squares of its digits. If multiple numbers yield the same maximum score, we should return the largest one. If no such number exists, we return an empty string.</p><h3 id=my-code-5>My Code<a hidden class=anchor aria-hidden=true href=#my-code-5>#</a></h3><p>To maximize the sum of squares of digits for a fixed sum, the digits should be as &ldquo;uneven&rdquo; as possible. For example, for a sum of 10, the digits 9 and 1 give a score of $9^2+1^2=82$, whereas 5 and 5 give $5^2+5^2=50$. This suggests a greedy approach: use as many 9s as possible. To make the resulting number as large as possible, these 9s should be placed in the most significant positions.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=display:flex><span>string Solution<span style=color:#f92672>::</span>maxSumOfSquares(<span style=color:#66d9ef>int</span> num, <span style=color:#66d9ef>int</span> sum) {
</span></span><span style=display:flex><span>    <span style=color:#75715e>// Create an output string stream for easy string building.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    ostringstream oss <span style=color:#f92672>=</span> {};
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>// A basic check for impossibility: the maximum possible sum for `num` digits
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#75715e>// is `9 * num`. If the required `sum` is greater, no solution exists.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>if</span>(<span style=color:#ae81ff>9</span> <span style=color:#f92672>*</span> num <span style=color:#f92672>&lt;</span> sum) {
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> <span style=color:#e6db74>&#34;&#34;</span>;
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>// `cnt` tracks how many digits we have placed so far.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>int</span> cnt <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>;
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e>// Greedily place as many &#39;9&#39;s as possible.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>while</span>(sum <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>9</span>) {
</span></span><span style=display:flex><span>        oss <span style=color:#f92672>&lt;&lt;</span> <span style=color:#ae81ff>9</span>; <span style=color:#75715e>// Add a &#39;9&#39; to our number.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        cnt<span style=color:#f92672>++</span>;    <span style=color:#75715e>// Increment the digit count.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        sum <span style=color:#f92672>-=</span> <span style=color:#ae81ff>9</span>; <span style=color:#75715e>// Decrease the remaining sum we need to achieve.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    }
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e>// After the loop, `sum` is between 0 and 9 (inclusive).
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#75715e>// This `sum` becomes the next digit.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    oss <span style=color:#f92672>&lt;&lt;</span> sum;
</span></span><span style=display:flex><span>    cnt<span style=color:#f92672>++</span>;
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e>// If we haven&#39;t reached the required `num` digits yet,
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#75715e>// the remaining digits must be &#39;0&#39;s.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>while</span>(num <span style=color:#f92672>-</span> cnt <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>0</span>) {
</span></span><span style=display:flex><span>        cnt<span style=color:#f92672>++</span>;
</span></span><span style=display:flex><span>        oss <span style=color:#f92672>&lt;&lt;</span> <span style=color:#ae81ff>0</span>;
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> oss.str();
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h3 id=my-solution-5>My Solution<a hidden class=anchor aria-hidden=true href=#my-solution-5>#</a></h3><p>The problem has two objectives layered on top of each other: first, maximize the sum of the squares of the digits, and second, among those with the maximal score, find the largest number. The constraints are a fixed number of digits (<code>num</code>) and a fixed sum of those digits (<code>sum</code>).</p><p>Let the digits of the number be $d_1, d_2, \dots, d_{\text{num}}$. We are given:</p><ol><li>$\sum_{i=1}^{\text{num}} d_i = \text{sum}$</li><li>$0 \le d_i \le 9$ for all $i$.</li></ol><p>We want to maximize the score $S = \sum_{i=1}^{\text{num}} d_i^2$.</p><p>The core mathematical insight here is that for a fixed sum, the sum of squares is maximized when the numbers are as far apart as possible. Consider two digits $a$ and $b$ with a sum $a+b=C$. If we change them to $a-1$ and $b+1$ (assuming $a>0, b&lt;9$), the new sum is still $C$, but the new sum of squares is $(a-1)^2 + (b+1)^2 = a^2 - 2a + 1 + b^2 + 2b + 1 = (a^2+b^2) + 2(b-a+1)$. If $b \ge a$, this change increases the sum of squares. This &ldquo;spreading out&rdquo; of values increases the sum of squares. We can generalize this: to maximize $\sum d_i^2$ subject to $\sum d_i = C$, we should make some $d_i$ as large as possible.</p><p>This insight leads to a greedy strategy. To maximize the score, we should make the digits as large as possible. The largest possible digit is 9. Therefore, our strategy should be to use as many 9s as we can. For each 9 we use, we satisfy 9 of the required <code>sum</code> and use up one of the <code>num</code> available digit slots.</p><p>My algorithm implements this greedy choice. It repeatedly appends the digit &lsquo;9&rsquo; to the result, subtracting 9 from the remaining <code>sum</code> each time, until the remaining <code>sum</code> is 9 or less. At this point, the remaining <code>sum</code> (which is between 0 and 9) must be used as the next digit. After placing this digit, if we still have not used up all <code>num</code> digit slots, the remaining slots must be filled with &lsquo;0&rsquo;s, as using any other digit would alter the sum.</p><p>Now, let&rsquo;s consider the second objective: returning the largest number among those with the maximum score. A number is larger if its most significant digits (the ones on the left) are larger. My greedy approach of placing the 9s first, followed by the next largest digit, and then the 0s, naturally constructs the number in descending order of its digits. This ensures that the largest possible digits (the 9s) occupy the most significant positions, thus creating the lexicographically largest and numerically greatest number possible for that set of digits.</p><p>For example, if <code>num = 3</code> and <code>sum = 18</code>, my algorithm would generate <code>9</code>, then <code>9</code>, then the remaining sum is <code>0</code>. The digits are {9, 9, 0}. The number constructed is &ldquo;990&rdquo;. This number has the maximum possible score ($9^2+9^2+0^2 = 162$) and is the largest possible permutation of these digits.</p><p>There is an initial check for feasibility: <code>if (9 * num &lt; sum)</code>. The maximum possible sum for <code>num</code> digits is achieved if all digits are 9, which gives a sum of $9 \times \text{num}$. If the required <code>sum</code> exceeds this, it is impossible to form such a number, so the function correctly returns an empty string. The problem statement also implies a lower bound check is needed. The sum of digits must be at least 1 for a positive integer, which is covered by the constraints.</p><p>The formal proof of correctness for this greedy algorithm relies on an &ldquo;exchange argument&rdquo;.
Let our greedy solution produce a sequence of digits $G = (g_1, g_2, \dots, g_n)$, where $n=\text{num}$. Let $O = (o_1, o_2, \dots, o_n)$ be any other valid sequence of digits for an optimal solution. We want to show that the score of $G$ is at least as high as the score of $O$, and that the number formed by $G$ is at least as large as the number formed by $O$ if the scores are equal.
Assume the digits in both sequences are sorted in descending order for score analysis: $g_1&rsquo; \ge g_2&rsquo; \ge \dots$ and $o_1&rsquo; \ge o_2&rsquo; \ge \dots$. Our greedy algorithm produces the lexicographically largest possible sequence of digits that maximizes the sum of squares. Let&rsquo;s find the first index $i$ where $g_i&rsquo; \neq o_i&rsquo;$.
Since our algorithm picks the largest possible digits first, it must be that $g_i&rsquo; > o_i&rsquo;$. Since both sequences have the same sum, there must be some other index $j > i$ where $o_j&rsquo; > g_j&rsquo;$.
Consider the digits ${o_i&rsquo;, o_j&rsquo;}$. We have $o_i&rsquo; &lt; g_i&rsquo; \le 9$ and $o_j&rsquo; > g_j&rsquo; \ge 0$.
Let&rsquo;s modify the optimal solution $O$ by changing the pair $(o_i&rsquo;, o_j&rsquo;)$ to $(o_i&rsquo;+1, o_j&rsquo;-1)$. The sum of digits remains the same. The new sum of squares is $(o_i&rsquo;+1)^2 + (o_j&rsquo;-1)^2 = o_i&rsquo;^2 + 2o_i&rsquo; + 1 + o_j&rsquo;^2 - 2o_j&rsquo; + 1 = (o_i&rsquo;^2 + o_j&rsquo;^2) + 2(o_i&rsquo; - o_j&rsquo; + 1)$. Since $o_i&rsquo; &lt; o_j&rsquo;$ (because the sequence is sorted), $o_i&rsquo; - o_j&rsquo; + 1 \le 0$. This transformation might not increase the score.
Let&rsquo;s re-evaluate the core property. The function $f(x)=x^2$ is a convex function. For any set of numbers $d_i$ with $\sum d_i = C$, the sum $\sum d_i^2$ is maximized when the values are at the boundaries of their domain. So, we should use as many 9s and 0s as possible. My greedy choice of using 9s is correct. It makes some digits as large as possible (9), forcing others to be as small as possible (0s, and one remainder digit). This configuration maximizes the sum of squares. Any other configuration could be transformed into our greedy configuration by repeatedly taking 1 from a digit $d_i &lt; 9$ and adding it to a digit $d_j &lt; 9$ to make one of them larger. This &ldquo;robbing Peter to pay Paul&rdquo; strategy increases the sum of squares.
So, the set of digits produced by the greedy algorithm is optimal for the score. My algorithm also arranges these digits in descending order, which by definition produces the largest number. Thus, the algorithm is correct.</p><h3 id=time-and-space-complexity-5>Time and Space Complexity<a hidden class=anchor aria-hidden=true href=#time-and-space-complexity-5>#</a></h3><p><strong>Time Complexity:</strong>
The algorithm&rsquo;s runtime is determined by the number of digits <code>num</code> and the <code>sum</code>.</p><ol><li>The <code>while(sum > 9)</code> loop runs at most <code>sum / 9</code> times. In each iteration, it performs a constant number of operations (append, decrement, increment). So this part is $O(\text{sum})$.</li><li>The <code>while(num - cnt > 0)</code> loop runs at most <code>num</code> times. This part is $O(\text{num})$.
The total time complexity is therefore $O(\text{sum} + \text{num})$.</li></ol><p>Formally, let $T(\text{num}, \text{sum})$ be the running time.
The first loop runs $k_1 = \lfloor (\text{sum}-1)/9 \rfloor$ times.
The second loop runs $k_2 = \text{num} - k_1 - 1$ times.
The total work is proportional to $k_1 + k_2 = \text{num}-1$. However, building the string can take longer. If we assume appending to an <code>ostringstream</code> is amortized constant time, the logic holds. If it&rsquo;s proportional to the string length, it would be a sum of lengths from 1 to <code>num</code>, resulting in $O(\text{num}^2)$. But <code>ostringstream</code> is optimized. A simpler analysis bounds the total number of appends by <code>num</code>. The number of loops is bounded by <code>sum</code> and <code>num</code>. So $O(\text{sum} + \text{num})$ is a safe upper bound.</p><p><strong>Space Complexity:</strong>
The space used is primarily for the output string being built. The final string will have <code>num</code> digits. The <code>ostringstream</code> will use space proportional to the number of digits. Therefore, the space complexity is $O(\text{num})$.</p><p>Formally, $S(\text{num}, \text{sum})$ is the space for the <code>ostringstream</code>. Its final size is <code>num</code> characters. So $S(\text{num}, \text{sum}) = O(\text{num})$.</p><h2 id=minimum-operations-to-transform-array>Minimum Operations to Transform Array<a hidden class=anchor aria-hidden=true href=#minimum-operations-to-transform-array>#</a></h2><h3 id=the-problem-6>The Problem<a hidden class=anchor aria-hidden=true href=#the-problem-6>#</a></h3><p>This problem was presented as <code>minOperations</code> which takes two integer vectors, <code>nums1</code> and <code>nums2</code>. Based on the code, it seems to be a custom transformation problem. The goal is to calculate a &ldquo;cost&rdquo; or &ldquo;number of operations&rdquo;. The calculation involves a base cost, which is the sum of element-wise absolute differences between <code>nums1</code> and <code>drevantor</code>, and an additional cost related to a special value <code>extra</code>, which is the last element of <code>nums2</code>.</p><h3 id=my-code-6>My Code<a hidden class=anchor aria-hidden=true href=#my-code-6>#</a></h3><p>The code I wrote calculates a value based on a specific formula. It first computes a base step count by summing up all the <code>abs(nums1[i] - nums2[i])</code> differences. Then, it determines an additional cost related to the <code>extra</code> value. It finds the element in either <code>nums1</code> or <code>nums2</code> that is &ldquo;nearest&rdquo; to <code>extra</code>. An additional operation seems to be required, and its cost depends on whether <code>extra</code> falls between any <code>(nums1[i], nums2[i])</code> pair.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=display:flex><span><span style=color:#66d9ef>long</span> <span style=color:#66d9ef>long</span> Solution<span style=color:#f92672>::</span>minOperations(vector<span style=color:#f92672>&lt;</span><span style=color:#66d9ef>int</span><span style=color:#f92672>&gt;</span> <span style=color:#f92672>&amp;</span>nums1, vector<span style=color:#f92672>&lt;</span><span style=color:#66d9ef>int</span><span style=color:#f92672>&gt;</span> <span style=color:#f92672>&amp;</span>nums2) {
</span></span><span style=display:flex><span>    <span style=color:#75715e>// The &#39;extra&#39; value is defined as the last element of the second array.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>int</span> extra          <span style=color:#f92672>=</span> nums2.back();
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>long</span> <span style=color:#66d9ef>long</span> step_cnt <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>;
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e>// `nearest` will store the index of the element closest to `extra`.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>int</span> nearest        <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>;
</span></span><span style=display:flex><span>    <span style=color:#75715e>// `nearest_d` stores the minimum distance found so far.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>int</span> nearest_d      <span style=color:#f92672>=</span> INT_MAX;
</span></span><span style=display:flex><span>    <span style=color:#75715e>// `flag` will be true if `extra` is &#34;covered&#34; by any range [nums1[i], nums2[i]].
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>bool</span> flag          <span style=color:#f92672>=</span> false;
</span></span><span style=display:flex><span>    <span style=color:#75715e>// `status` indicates whether the nearest element was found in nums1 (1) or nums2 (2).
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>int</span> status         <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>;
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e>// Iterate through both arrays simultaneously.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>for</span>(<span style=color:#66d9ef>int</span> i <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; i <span style=color:#f92672>&lt;</span> nums1.size(); i<span style=color:#f92672>++</span>) {
</span></span><span style=display:flex><span>        <span style=color:#75715e>// Find the element in either array that is closest to `extra`.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        <span style=color:#66d9ef>if</span>(abs(nums1[i] <span style=color:#f92672>-</span> extra) <span style=color:#f92672>&lt;</span> nearest_d) {
</span></span><span style=display:flex><span>            nearest   <span style=color:#f92672>=</span> i;
</span></span><span style=display:flex><span>            status    <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>;
</span></span><span style=display:flex><span>            nearest_d <span style=color:#f92672>=</span> abs(nums1[i] <span style=color:#f92672>-</span> extra);
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span>(abs(nums2[i] <span style=color:#f92672>-</span> extra) <span style=color:#f92672>&lt;</span> nearest_d) {
</span></span><span style=display:flex><span>            nearest   <span style=color:#f92672>=</span> i;
</span></span><span style=display:flex><span>            status    <span style=color:#f92672>=</span> <span style=color:#ae81ff>2</span>;
</span></span><span style=display:flex><span>            nearest_d <span style=color:#f92672>=</span> abs(nums2[i] <span style=color:#f92672>-</span> extra);
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e>// Check if `extra` lies within the closed interval defined by nums1[i] and nums2[i].
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        <span style=color:#66d9ef>if</span>((nums1[i] <span style=color:#f92672>&lt;=</span> extra <span style=color:#f92672>&amp;&amp;</span> extra <span style=color:#f92672>&lt;=</span> nums2[i]) <span style=color:#f92672>||</span> (nums2[i] <span style=color:#f92672>&lt;=</span> extra <span style=color:#f92672>&amp;&amp;</span> extra <span style=color:#f92672>&lt;=</span> nums1[i])) {
</span></span><span style=display:flex><span>            flag <span style=color:#f92672>=</span> true;
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e>// Accumulate the base cost, which is the sum of element-wise differences.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        step_cnt <span style=color:#f92672>+=</span> abs(nums1[i] <span style=color:#f92672>-</span> nums2[i]);
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e>// Determine the final cost based on the `flag` and `status`.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>if</span>(flag) {
</span></span><span style=display:flex><span>        <span style=color:#75715e>// If `extra` was covered, the cost is the base cost plus 1.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        <span style=color:#66d9ef>return</span> step_cnt <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>;
</span></span><span style=display:flex><span>    } <span style=color:#66d9ef>else</span> <span style=color:#a6e22e>if</span>(status <span style=color:#f92672>==</span> <span style=color:#ae81ff>1</span>) {
</span></span><span style=display:flex><span>        <span style=color:#75715e>// If not covered, and the nearest element was in nums1, add 1 and the distance.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        <span style=color:#66d9ef>return</span> step_cnt <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span> <span style=color:#f92672>+</span> abs(nums1[nearest] <span style=color:#f92672>-</span> extra);
</span></span><span style=display:flex><span>    } <span style=color:#66d9ef>else</span> { <span style=color:#75715e>// status == 2
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        <span style=color:#75715e>// If not covered, and the nearest element was in nums2, add 1 and the distance.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        <span style=color:#66d9ef>return</span> step_cnt <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span> <span style=color:#f92672>+</span> abs(nums2[nearest] <span style=color:#f92672>-</span> extra);
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h3 id=my-solution-6>My Solution<a hidden class=anchor aria-hidden=true href=#my-solution-6>#</a></h3><p>This problem appears to define a unique cost function for transforming <code>nums1</code> into <code>nums2</code> with a special consideration for an <code>extra</code> value. My solution meticulously implements the calculation of this cost as defined by the underlying (unseen) problem logic. Let&rsquo;s break down the components of the cost and rationalize the logic.</p><p>The core of the problem seems to be about transforming <code>nums1</code> to <code>nums2</code>. A common way to measure the &ldquo;distance&rdquo; or &ldquo;cost of transformation&rdquo; between two arrays is the sum of absolute differences, also known as the Manhattan distance or $L_1$ norm of the difference vector. The line <code>step_cnt += abs(nums1[i] - nums2[i]);</code> calculates this base cost. This can be interpreted as the minimum number of increment/decrement operations needed to make <code>nums1[i]</code> equal to <code>nums2[i]</code> for all <code>i</code>.</p><p>The complexity arises from the special role of <code>extra = nums2.back()</code>. The final cost is not just <code>step_cnt</code>. There is an additional component. My algorithm&rsquo;s logic suggests this is a &ldquo;connection cost&rdquo; to the <code>extra</code> value.</p><p>The code iterates through the arrays to determine two things regarding <code>extra</code>:</p><ol><li><strong>Coverage (<code>flag</code>):</strong> It checks if <code>extra</code> is contained within any of the intervals <code>[min(nums1[i], nums2[i]), max(nums1[i], nums2[i])]</code>. If it is, the boolean <code>flag</code> is set to <code>true</code>. This suggests that if <code>extra</code> can be &ldquo;formed&rdquo; by a value between <code>nums1[i]</code> and <code>nums2[i]</code>, the connection cost is minimal.</li><li><strong>Proximity (<code>nearest</code>, <code>nearest_d</code>, <code>status</code>):</strong> Concurrently, it finds the element across both <code>nums1</code> and <code>nums2</code> that is numerically closest to <code>extra</code>. It records the index (<code>nearest</code>), the minimum distance (<code>nearest_d</code>), and which array the element came from (<code>status</code>). This seems to be a fallback plan for calculating the connection cost if the &ldquo;coverage&rdquo; condition is not met.</li></ol><p>The final return statement synthesizes these findings:</p><ul><li><code>if (flag)</code>: If <code>extra</code> was &ldquo;covered&rdquo; by at least one interval, the total cost is <code>step_cnt + 1</code>. This can be interpreted as: the base transformation cost, plus a single operation to &ldquo;activate&rdquo; the connection to <code>extra</code>, which is cheap because it&rsquo;s already within range.</li><li><code>else</code>: If <code>extra</code> was not covered, the cost is higher. It is <code>step_cnt + 1 + nearest_d</code>. This implies: the base transformation cost, plus one activation operation, plus an additional cost equal to the minimum distance to <code>extra</code>. This additional cost represents the effort needed to &ldquo;pull&rdquo; the nearest existing value towards <code>extra</code> to establish the connection.</li></ul><p>The correctness of this solution is predicated on it being a correct implementation of the specific, custom cost function defined by the problem. Assuming the problem is to calculate this exact cost, my algorithm is correct because it systematically computes each component of the formula.</p><ul><li>It correctly accumulates the sum of absolute differences.</li><li>It correctly iterates through all elements to check for the coverage condition and updates the <code>flag</code> appropriately.</li><li>It correctly maintains the minimum distance to <code>extra</code> and the location of the element that achieves this minimum distance.</li><li>It uses a conditional structure that correctly applies the final formula based on the computed <code>flag</code> and <code>status</code>.</li></ul><p>Let&rsquo;s formalize the cost function $C$ that the algorithm computes.
Let $S = \sum_{i=0}^{n-1} |nums1_i - nums2_i|$.
Let $E = nums2_{n-1}$.
Let the &ldquo;coverage&rdquo; predicate be $P = \exists i \in [0, n-1] \text{ s.t. } (E \ge \min(nums1_i, nums2_i)) \land (E \le \max(nums1_i, nums2_i))$.
Let $d_{min} = \min_{i \in [0, n-1]} (\min(|nums1_i - E|, |nums2_i - E|))$.
The algorithm computes the cost $C$ as:
$C = \begin{cases} S + 1 & \text{if } P \text{ is true} \ S + 1 + d_{min} & \text{if } P \text{ is false} \end{cases}$
My code is a direct and correct implementation of this function. The loops ensure that all $i$ are checked for the existence condition $P$ and that the minimum distance $d_{min}$ is found. The final <code>if-else</code> block correctly applies the two cases of the piecewise function.</p><h3 id=time-and-space-complexity-6>Time and Space Complexity<a hidden class=anchor aria-hidden=true href=#time-and-space-complexity-6>#</a></h3><p><strong>Time Complexity:</strong>
The algorithm is dominated by a single <code>for</code> loop that iterates through the arrays from <code>i = 0</code> to <code>nums1.size() - 1</code>. Let $n$ be the size of the arrays. The loop runs $n$ times.
Inside the loop, all operations are constant time:</p><ul><li>Absolute value calculations.</li><li>Comparisons.</li><li>Assignments.</li><li>Arithmetic operations.
Therefore, the work done inside the loop is $O(1)$. The total time complexity is $n$ times this constant work, which is $O(n)$.</li></ul><p>Formally, let $T(n)$ be the running time.
$T(n) = \sum_{i=0}^{n-1} C$, where $C$ is the constant cost of the operations inside the loop.
$T(n) = n \cdot C = O(n)$.</p><p><strong>Space Complexity:</strong>
The algorithm uses a handful of variables (<code>extra</code>, <code>step_cnt</code>, <code>nearest</code>, <code>nearest_d</code>, <code>flag</code>, <code>status</code>) to store intermediate values. The amount of memory used is constant and does not depend on the size of the input arrays. Therefore, the space complexity is $O(1)$ (not including the space for the input arrays themselves).</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://tategotoazarasi.github.io/en/tags/competitive-programming/>Competitive-Programming</a></li><li><a href=https://tategotoazarasi.github.io/en/tags/cpp/>Cpp</a></li><li><a href=https://tategotoazarasi.github.io/en/tags/algorithm-analysis/>Algorithm-Analysis</a></li><li><a href=https://tategotoazarasi.github.io/en/tags/time-complexity/>Time-Complexity</a></li><li><a href=https://tategotoazarasi.github.io/en/tags/space-complexity/>Space-Complexity</a></li><li><a href=https://tategotoazarasi.github.io/en/tags/formal-proof/>Formal-Proof</a></li><li><a href=https://tategotoazarasi.github.io/en/tags/graph-theory/>Graph-Theory</a></li><li><a href=https://tategotoazarasi.github.io/en/tags/weak-vertices/>Weak-Vertices</a></li><li><a href=https://tategotoazarasi.github.io/en/tags/triangle-finding/>Triangle-Finding</a></li><li><a href=https://tategotoazarasi.github.io/en/tags/disjoint-set-union/>Disjoint-Set-Union</a></li><li><a href=https://tategotoazarasi.github.io/en/tags/union-find/>Union-Find</a></li><li><a href=https://tategotoazarasi.github.io/en/tags/connectivity/>Connectivity</a></li><li><a href=https://tategotoazarasi.github.io/en/tags/shortest-path/>Shortest-Path</a></li><li><a href=https://tategotoazarasi.github.io/en/tags/bfs/>Bfs</a></li><li><a href=https://tategotoazarasi.github.io/en/tags/grid-traversal/>Grid-Traversal</a></li><li><a href=https://tategotoazarasi.github.io/en/tags/recursion/>Recursion</a></li><li><a href=https://tategotoazarasi.github.io/en/tags/backtracking/>Backtracking</a></li><li><a href=https://tategotoazarasi.github.io/en/tags/subset-sum-problem/>Subset-Sum-Problem</a></li><li><a href=https://tategotoazarasi.github.io/en/tags/greedy-algorithms/>Greedy-Algorithms</a></li><li><a href=https://tategotoazarasi.github.io/en/tags/number-theory/>Number-Theory</a></li><li><a href=https://tategotoazarasi.github.io/en/tags/leetcode/>Leetcode</a></li></ul><nav class=paginav><a class=prev href=https://tategotoazarasi.github.io/en/posts/building-a-resilient-typescript-video-downloader-against-advanced-anti-scraping/><span class=title>« Prev</span><br><span>Building a TypeScript Video Downloader for Complex, Anti-Scraping Websites</span>
</a><a class=next href=https://tategotoazarasi.github.io/en/posts/uol-2025-wk2/><span class=title>Next »</span><br><span>Uol 2025 Wk2 Solutions</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://tategotoazarasi.github.io/en/>Tategoto Azarasi</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>