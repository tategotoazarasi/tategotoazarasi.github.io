<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Pol on Harp Seal Pup Nursery and Caring Center</title><link>https://tategotoazarasi.github.io/tags/pol/</link><description>Recent content in Pol on Harp Seal Pup Nursery and Caring Center</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Mon, 20 May 2024 13:52:09 +0000</lastBuildDate><atom:link href="https://tategotoazarasi.github.io/tags/pol/index.xml" rel="self" type="application/rss+xml"/><item><title>如何使用Python去重考研政治选择题库</title><link>https://tategotoazarasi.github.io/post/how-to-use-python-to-remove-duplicates-from-the-postgraduate-political-science-question-bank/</link><pubDate>Mon, 20 May 2024 21:39:12 +0800</pubDate><guid>https://tategotoazarasi.github.io/post/how-to-use-python-to-remove-duplicates-from-the-postgraduate-political-science-question-bank/</guid><description>在准备考研政治时，积累大量的选择题是非常重要的。然而，重复的题目不仅浪费时间，还影响复习效率。考研政治是考研复习中的重要一环，大量的选择题可以帮助考生更好地掌握知识点，但在积累题库的过程中，往往会出现大量重复的题目。这些重复题目不仅占用存储空间，还浪费考生宝贵的复习时间，影响复习效率。因此，对题库进行去重变得尤为重要。本文将介绍两种基于Python的去重方法，帮助您轻松清理重复题目，从而更高效地备战考研。通过去重，我们可以确保题库的独特性，提高复习的针对性和效率，为考生提供更好的复习体验和更高的考试通过率。
为了解决考研政治选择题库中的重复问题，我们采用了两种不同的去重方法：基于MD5哈希和基于BERT相似度。这两种方法各有优缺点，结合使用可以更全面地清理题库中的重复题目。
方法一：基于MD5哈希去重 MD5是一种常用的消息摘要算法，可以将任意长度的数据转换为固定长度的哈希值。通过对题目的各个部分（选项、备注、问题）进行预处理，然后计算它们的MD5哈希值，我们可以快速检测到重复的题目。对于重复的文本内容，MD5算法会生成相同的哈希值，因此，通过计算题目的MD5哈希值，可以快速识别并删除重复的题目。此方法的优点是速度快、实现简单，但对于相似但不完全相同的题目（例如选项顺序不同）可能无法检测到。
实现步骤
预处理字符串：为了确保对比的准确性，需要对题目内容进行标准化处理。具体步骤包括：转换为小写、移除HTML标签、替换连续的空白字符为单个空格、移除前后空白。 计算MD5哈希值：将标准化后的题目各部分（选项、备注、问题）进行编码，并计算其MD5哈希值，再将这些哈希值转换为整数并相加，生成唯一的哈希值。 去重：使用集合（set）来存储已经处理过的哈希值。如果某个题目的哈希值已经存在于集合中，则说明它是重复的，删除该题目；否则，将其哈希值添加到集合中。 import hashlib import regex from bs4 import BeautifulSoup from main import invoke s_options = set() s_remark = set() s_question = set() def process_string(str_): str_ = str_.lower() str_ = BeautifulSoup(str_, &amp;#34;html.parser&amp;#34;).get_text() str_ = regex.sub(r&amp;#34;[^\p{Script=Han}\p{Script=Latin}\p{Number}]&amp;#34;, &amp;#34;&amp;#34;, str_) str_ = str_.strip() return str_ def calculate_md5(strings): result = 0 for string in strings: encoded_string = string.encode() md5_hash = hashlib.md5(encoded_string) int_hash = int(md5_hash.hexdigest(), 16) result += int_hash return result if __name__ == &amp;#34;__main__&amp;#34;: notesId = invoke(&amp;#34;findNotes&amp;#34;, query=&amp;#34;deck:考研政治&amp;#34;) notesInfo = invoke(&amp;#34;notesInfo&amp;#34;, notes=notesId) for noteInfo in notesInfo: fields = noteInfo[&amp;#34;fields&amp;#34;] strs = [ process_string(fields[&amp;#34;A&amp;#34;][&amp;#34;value&amp;#34;]), process_string(fields[&amp;#34;B&amp;#34;][&amp;#34;value&amp;#34;]), process_string(fields[&amp;#34;C&amp;#34;][&amp;#34;value&amp;#34;]), process_string(fields[&amp;#34;D&amp;#34;][&amp;#34;value&amp;#34;]), process_string(fields[&amp;#34;E&amp;#34;][&amp;#34;value&amp;#34;]), process_string(fields[&amp;#34;F&amp;#34;][&amp;#34;value&amp;#34;]), process_string(fields[&amp;#34;G&amp;#34;][&amp;#34;value&amp;#34;]), process_string(fields[&amp;#34;H&amp;#34;][&amp;#34;value&amp;#34;]), process_string(fields[&amp;#34;I&amp;#34;][&amp;#34;value&amp;#34;]), ] md5v = str(calculate_md5(strs)) if md5v in s_options: invoke(&amp;#34;deleteNotes&amp;#34;, notes=[noteInfo[&amp;#34;noteId&amp;#34;]]) else: s_options.</description></item></channel></rss>